{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1-y7o-QRWp-OwGMe64CxQwQk2-o2jZFm3","timestamp":1681478853692}],"machine_shape":"hm","gpuType":"V100"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"d3c4e155b9674147bb0dfe0d27317d73":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d3ea5527da7145289d341539f058f84d","IPY_MODEL_8cb02ce6efab4a93904e3764e149af70","IPY_MODEL_db9f5b1633894ad3b7b50cac1485be64"],"layout":"IPY_MODEL_dc21f2fe7b2b4772b4e804548e470b34"}},"d3ea5527da7145289d341539f058f84d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_96892d420d454f48b80e773e41aceead","placeholder":"​","style":"IPY_MODEL_0f03416fe3fc4d8bb80f818943017004","value":"Downloading (…)okenizer_config.json: 100%"}},"8cb02ce6efab4a93904e3764e149af70":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_377c5de7fcc8428bb60b8edf7ba64030","max":467,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a3bac4b449574337b16b6d5668668322","value":467}},"db9f5b1633894ad3b7b50cac1485be64":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_44b89ec419974d729089fe6cfe7febf8","placeholder":"​","style":"IPY_MODEL_40389029c595408593c75f9c0279d659","value":" 467/467 [00:00&lt;00:00, 39.6kB/s]"}},"dc21f2fe7b2b4772b4e804548e470b34":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96892d420d454f48b80e773e41aceead":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f03416fe3fc4d8bb80f818943017004":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"377c5de7fcc8428bb60b8edf7ba64030":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a3bac4b449574337b16b6d5668668322":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"44b89ec419974d729089fe6cfe7febf8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40389029c595408593c75f9c0279d659":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"72946a7f14a44568a39db3d3535f0069":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4b5b00c052aa407b8a44978154a52c7d","IPY_MODEL_ef5b135b3dd44b66877f6023708aba2c","IPY_MODEL_3df1e745b8ff426793b95d1a166da592"],"layout":"IPY_MODEL_bf9f0968ecf94237bfe2003b9a15eb6b"}},"4b5b00c052aa407b8a44978154a52c7d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8d5643c9d2d44e3f8dca5b7fe6526d45","placeholder":"​","style":"IPY_MODEL_4f338671547844f0ab29d7f56aacdedd","value":"Downloading spm.model: 100%"}},"ef5b135b3dd44b66877f6023708aba2c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_787f3e19fc4743d39227a271e3c554a2","max":4305025,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f7b2d4652234473a884214279949307d","value":4305025}},"3df1e745b8ff426793b95d1a166da592":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e810fe91cf4c4a6db464f513278b8a9b","placeholder":"​","style":"IPY_MODEL_9104eff747e34d19b82556f224ce45e5","value":" 4.31M/4.31M [00:00&lt;00:00, 54.0MB/s]"}},"bf9f0968ecf94237bfe2003b9a15eb6b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d5643c9d2d44e3f8dca5b7fe6526d45":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f338671547844f0ab29d7f56aacdedd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"787f3e19fc4743d39227a271e3c554a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7b2d4652234473a884214279949307d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e810fe91cf4c4a6db464f513278b8a9b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9104eff747e34d19b82556f224ce45e5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4032e6a4ced44536b51128718fadc545":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e9e9bdf7fba94c6c9ffcabec8623b5df","IPY_MODEL_78590a4552a1407f854b68b00e2fba36","IPY_MODEL_592b1ce982364ecfa577ff59d1b87ec2"],"layout":"IPY_MODEL_f4f39c9872ac450fa6b732606b4c890e"}},"e9e9bdf7fba94c6c9ffcabec8623b5df":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9982d37549284eec99a13b9d55af72ee","placeholder":"​","style":"IPY_MODEL_56e0673586114570a396d8bae70e0429","value":"Downloading tokenizer.json: 100%"}},"78590a4552a1407f854b68b00e2fba36":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7126fa67c0754d61b6b0839e9094e99d","max":16316151,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8c7ea93a1e40459e934410ad8a004c4e","value":16316151}},"592b1ce982364ecfa577ff59d1b87ec2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_512210131d1941849cb15f79fae08329","placeholder":"​","style":"IPY_MODEL_543d49cf129941e6b91f1ea1ea8002ce","value":" 16.3M/16.3M [00:00&lt;00:00, 39.9MB/s]"}},"f4f39c9872ac450fa6b732606b4c890e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9982d37549284eec99a13b9d55af72ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"56e0673586114570a396d8bae70e0429":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7126fa67c0754d61b6b0839e9094e99d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c7ea93a1e40459e934410ad8a004c4e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"512210131d1941849cb15f79fae08329":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"543d49cf129941e6b91f1ea1ea8002ce":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2be9fee833004d9f9facaaa31c50d485":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1076dd647a4c4adbbf69c4fafd822b0f","IPY_MODEL_f7c9ae27a4054809977178df56472d84","IPY_MODEL_23ae5ae1648a4415b7f29850391d58ee"],"layout":"IPY_MODEL_532f548ace934b9c9d6288885063096a"}},"1076dd647a4c4adbbf69c4fafd822b0f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4052feb7c34748fea09b6e8454fa5f33","placeholder":"​","style":"IPY_MODEL_7825f37f54084907868d2297eaae558d","value":"Downloading (…)in/added_tokens.json: 100%"}},"f7c9ae27a4054809977178df56472d84":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_870f9fc0ad3145d78db9e5d5d0987fb4","max":23,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8e3434dc62da4ad2bb002469343ff7fc","value":23}},"23ae5ae1648a4415b7f29850391d58ee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad5fc0ed2ee740ac8deebd34711426d5","placeholder":"​","style":"IPY_MODEL_3167b40fa71f4ab8a987e70cfbd538c3","value":" 23.0/23.0 [00:00&lt;00:00, 2.05kB/s]"}},"532f548ace934b9c9d6288885063096a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4052feb7c34748fea09b6e8454fa5f33":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7825f37f54084907868d2297eaae558d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"870f9fc0ad3145d78db9e5d5d0987fb4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e3434dc62da4ad2bb002469343ff7fc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ad5fc0ed2ee740ac8deebd34711426d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3167b40fa71f4ab8a987e70cfbd538c3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a3570d2b59fa4d079c8284a7783affed":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_668ef27d364249f8bedc3ba5aa4082ca","IPY_MODEL_fe74659f7449485aa94f5f37bdff0400","IPY_MODEL_547e4589d8334dccbad71cbe3eb4e087"],"layout":"IPY_MODEL_2e8d8f2ba2f049d48019be72ac648287"}},"668ef27d364249f8bedc3ba5aa4082ca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ea3fcacd70e64675b7896ab3ee172f2d","placeholder":"​","style":"IPY_MODEL_98835fad94ee4464bbb640f9580c0b61","value":"Downloading (…)cial_tokens_map.json: 100%"}},"fe74659f7449485aa94f5f37bdff0400":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_92a61437427f44a0b3369b2cb78467fb","max":173,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5b47ad85fc354b0caa4e111bf5828cc2","value":173}},"547e4589d8334dccbad71cbe3eb4e087":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4fb8bd5f61024243bac7d4feff186fd3","placeholder":"​","style":"IPY_MODEL_b2af99791472490ea2e1645da1252e47","value":" 173/173 [00:00&lt;00:00, 14.4kB/s]"}},"2e8d8f2ba2f049d48019be72ac648287":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea3fcacd70e64675b7896ab3ee172f2d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"98835fad94ee4464bbb640f9580c0b61":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"92a61437427f44a0b3369b2cb78467fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b47ad85fc354b0caa4e111bf5828cc2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4fb8bd5f61024243bac7d4feff186fd3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2af99791472490ea2e1645da1252e47":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"94a1d5cb1c8a438ba7d8774459946ed8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ea72dd515ecb45b0863fbf3670031769","IPY_MODEL_fa0d7d1aa4594c6bbb71a70191fcfe1f","IPY_MODEL_929326ec85364a65973a408c47ea5152"],"layout":"IPY_MODEL_6d53ea949469425ca7cfe414d335579a"}},"ea72dd515ecb45b0863fbf3670031769":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_785804d02ac147e2873dcb39a17a812c","placeholder":"​","style":"IPY_MODEL_da500e48711842769edab63d7b52191e","value":"Downloading (…)lve/main/config.json: 100%"}},"fa0d7d1aa4594c6bbb71a70191fcfe1f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_34dd8ff2555d41fcb1b4ab6d591da849","max":1093,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4bcde223b2c945ee89bcbe7a60d1d4ef","value":1093}},"929326ec85364a65973a408c47ea5152":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8c1cf07d021441d3bfaa534e0f9d4293","placeholder":"​","style":"IPY_MODEL_d93f0f360b07430a8b3597a84d2deddd","value":" 1.09k/1.09k [00:00&lt;00:00, 94.8kB/s]"}},"6d53ea949469425ca7cfe414d335579a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"785804d02ac147e2873dcb39a17a812c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"da500e48711842769edab63d7b52191e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"34dd8ff2555d41fcb1b4ab6d591da849":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4bcde223b2c945ee89bcbe7a60d1d4ef":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8c1cf07d021441d3bfaa534e0f9d4293":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d93f0f360b07430a8b3597a84d2deddd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f29f69d00dcb4f399be3e14db2de1740":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_66b75869c6a44caf978e802c8a646144","IPY_MODEL_5cda777958c7483d9b8b0d64394a349a","IPY_MODEL_e5496521b0fe4dd0b62e9174b88e3552"],"layout":"IPY_MODEL_c85d0f5661fa4f31bbe56e0a9421cd48"}},"66b75869c6a44caf978e802c8a646144":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cda13ee8d7ce4a208c3915d3ed904558","placeholder":"​","style":"IPY_MODEL_e7f0bb04762f40e38ee89709353d389e","value":"Downloading pytorch_model.bin: 100%"}},"5cda777958c7483d9b8b0d64394a349a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7daf6faf49804b9391cf25b24129d5df","max":557692715,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9ba06cd560604193900982934656da98","value":557692715}},"e5496521b0fe4dd0b62e9174b88e3552":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5b401d8bdce746d7b969e6895f6add5c","placeholder":"​","style":"IPY_MODEL_eadbc44518994e75a5ea64755b4747b0","value":" 558M/558M [00:04&lt;00:00, 57.5MB/s]"}},"c85d0f5661fa4f31bbe56e0a9421cd48":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cda13ee8d7ce4a208c3915d3ed904558":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e7f0bb04762f40e38ee89709353d389e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7daf6faf49804b9391cf25b24129d5df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ba06cd560604193900982934656da98":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5b401d8bdce746d7b969e6895f6add5c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eadbc44518994e75a5ea64755b4747b0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0e38879956e14dcdbbee23802bfd7dcf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8c32fc01be9c42b2b2cbb094a09f5b7a","IPY_MODEL_093c102538664c4ea40ef5e7146c21ca","IPY_MODEL_4644a9e6e89141dfad120c3f700b31be"],"layout":"IPY_MODEL_3728ddd607984b38bae8d5e1ac518c8c"}},"8c32fc01be9c42b2b2cbb094a09f5b7a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2abe4417632d465484830374534dd12e","placeholder":"​","style":"IPY_MODEL_98caa2c3e6724a96abe6ae38d361b79f","value":"100%"}},"093c102538664c4ea40ef5e7146c21ca":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3eb7ac36ec1d4f8582b451f34cfd9179","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d37f75af80834b7ba8c0085e5269e739","value":3}},"4644a9e6e89141dfad120c3f700b31be":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_914205e2d3df48339251865558ffa288","placeholder":"​","style":"IPY_MODEL_2177973e7a7b4c3ba28d62809ae3d291","value":" 3/3 [00:00&lt;00:00,  4.13ba/s]"}},"3728ddd607984b38bae8d5e1ac518c8c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2abe4417632d465484830374534dd12e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"98caa2c3e6724a96abe6ae38d361b79f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3eb7ac36ec1d4f8582b451f34cfd9179":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d37f75af80834b7ba8c0085e5269e739":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"914205e2d3df48339251865558ffa288":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2177973e7a7b4c3ba28d62809ae3d291":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"049003993aec40f3ade2bb0610f30b0f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_68982a5d5dee4fd198e0dd0205cb8d14","IPY_MODEL_8a3f0775cc4a421b8078894cdce4113e","IPY_MODEL_23e4cd6f159a42308a0760e68825717d"],"layout":"IPY_MODEL_12f3e981af3a49e78a929e1f7b28b834"}},"68982a5d5dee4fd198e0dd0205cb8d14":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_093d7ac6b0e043329bedbdd505800318","placeholder":"​","style":"IPY_MODEL_cb30854187a44c04b560065c0f3ddba6","value":"100%"}},"8a3f0775cc4a421b8078894cdce4113e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c2d4b37c056d4147bd9e43a0ff6b728c","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7d67969b989a4077a3c8226d1083ee27","value":1}},"23e4cd6f159a42308a0760e68825717d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ed066fa4b8f4a14a4a55f00a6515b7c","placeholder":"​","style":"IPY_MODEL_d58f9216bad54501bc566910f47e894a","value":" 1/1 [00:00&lt;00:00,  5.69ba/s]"}},"12f3e981af3a49e78a929e1f7b28b834":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"093d7ac6b0e043329bedbdd505800318":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb30854187a44c04b560065c0f3ddba6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c2d4b37c056d4147bd9e43a0ff6b728c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d67969b989a4077a3c8226d1083ee27":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0ed066fa4b8f4a14a4a55f00a6515b7c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d58f9216bad54501bc566910f47e894a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ad8c2d75866a4828904cc1f95e5f4143":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2cc7cf13e1e244dc82659f89e806f46b","IPY_MODEL_2afd469f38184b3aaec858ef59e2c8e1","IPY_MODEL_4ddc96ba65324a85a260548cc09e0128"],"layout":"IPY_MODEL_4306cc94287d4fccaac63a7684f8146f"}},"2cc7cf13e1e244dc82659f89e806f46b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0f4e580d654546c8b411101da1d40e50","placeholder":"​","style":"IPY_MODEL_fa17249c28d649d1ad9a8de752230cf3","value":"Casting the dataset: 100%"}},"2afd469f38184b3aaec858ef59e2c8e1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2ffbb43b63d44ffd88b7c9ae27fed265","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e678c6640f634ed1b56078a8b11bffc2","value":1}},"4ddc96ba65324a85a260548cc09e0128":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_64d91991852b43adaa9e3ec5c55e70d5","placeholder":"​","style":"IPY_MODEL_8e70198a56c344548254f02f297ea3d9","value":" 1/1 [00:00&lt;00:00,  3.30ba/s]"}},"4306cc94287d4fccaac63a7684f8146f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f4e580d654546c8b411101da1d40e50":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa17249c28d649d1ad9a8de752230cf3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2ffbb43b63d44ffd88b7c9ae27fed265":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e678c6640f634ed1b56078a8b11bffc2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"64d91991852b43adaa9e3ec5c55e70d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e70198a56c344548254f02f297ea3d9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"47d561ab7bd9432794f1b702dd97b5a4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0e7a44c50ba1407aae35deb92788513a","IPY_MODEL_dce2131f5ccb4506a65e340a02186547","IPY_MODEL_66a76081ea1d4f5780e2b38df661164d"],"layout":"IPY_MODEL_177506cd9e3c46018af39a37c2a9bac5"}},"0e7a44c50ba1407aae35deb92788513a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b5506a3947394707a00ccb0d0b720088","placeholder":"​","style":"IPY_MODEL_ce9b371b7f8f4c4e9b17b8c4b297cdea","value":"Casting the dataset: 100%"}},"dce2131f5ccb4506a65e340a02186547":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ec60d37faa6e41bc832f93b487c4a72f","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a2b599365e9e401190ef7ce4089616c8","value":1}},"66a76081ea1d4f5780e2b38df661164d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ba008df7455e4de781da40c70c0deaf7","placeholder":"​","style":"IPY_MODEL_47891fd76d094e7faf4cf4e576af04fc","value":" 1/1 [00:00&lt;00:00,  7.70ba/s]"}},"177506cd9e3c46018af39a37c2a9bac5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5506a3947394707a00ccb0d0b720088":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce9b371b7f8f4c4e9b17b8c4b297cdea":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ec60d37faa6e41bc832f93b487c4a72f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a2b599365e9e401190ef7ce4089616c8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ba008df7455e4de781da40c70c0deaf7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"47891fd76d094e7faf4cf4e576af04fc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dfba2da0c2d948c6867083a6355eefca":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e7139293e45342e082e90a22b457e1e4","IPY_MODEL_a07173df610e40cca5ad7bf9ad658272","IPY_MODEL_d1e0069fb7db491ea20620373b75cb0d"],"layout":"IPY_MODEL_cf556d87499140cba08524d3b9102c3f"}},"e7139293e45342e082e90a22b457e1e4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_70e55260058f454d916077b858f7f997","placeholder":"​","style":"IPY_MODEL_164bf5707e664884b2370a7ad7e581cd","value":"100%"}},"a07173df610e40cca5ad7bf9ad658272":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a53aae2f6a3543d9a710b3a05bcd630b","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_abc1666d68884147a00bf4792e1be604","value":3}},"d1e0069fb7db491ea20620373b75cb0d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6428a7f1d1e24d9bbe7165b998ec35e9","placeholder":"​","style":"IPY_MODEL_8eedaae0bd954a44a69c98786aada1ca","value":" 3/3 [00:00&lt;00:00,  5.23ba/s]"}},"cf556d87499140cba08524d3b9102c3f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"70e55260058f454d916077b858f7f997":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"164bf5707e664884b2370a7ad7e581cd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a53aae2f6a3543d9a710b3a05bcd630b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"abc1666d68884147a00bf4792e1be604":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6428a7f1d1e24d9bbe7165b998ec35e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8eedaae0bd954a44a69c98786aada1ca":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"af9563d8679d4995b7f76366c40953dd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8e416623d1d0460ab46d0eb89b3a3fe9","IPY_MODEL_df9eb808b63b4bb186500b9606a9f123","IPY_MODEL_b8713d3dbc224f7c82e9d3330c5889ac"],"layout":"IPY_MODEL_66eb1079c71e4c2cac0cbf7719c476aa"}},"8e416623d1d0460ab46d0eb89b3a3fe9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a8a4789437884773bacda06caee6c01e","placeholder":"​","style":"IPY_MODEL_e5a254b5ee96492ba17a5c7628128bf0","value":"100%"}},"df9eb808b63b4bb186500b9606a9f123":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_12fe2a1f7c844fb1b58bc8cc6324d202","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2456cd23f24c4bff999041b17756336c","value":1}},"b8713d3dbc224f7c82e9d3330c5889ac":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3acf90dd75584f3483faf61c259f398b","placeholder":"​","style":"IPY_MODEL_f9c66f76dbc54197893237654bc13000","value":" 1/1 [00:00&lt;00:00,  6.13ba/s]"}},"66eb1079c71e4c2cac0cbf7719c476aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a8a4789437884773bacda06caee6c01e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e5a254b5ee96492ba17a5c7628128bf0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"12fe2a1f7c844fb1b58bc8cc6324d202":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2456cd23f24c4bff999041b17756336c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3acf90dd75584f3483faf61c259f398b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f9c66f76dbc54197893237654bc13000":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["## Code to train the BERT-NLI Outgroup Hostility model\n","### **❗This notebook was copied from the Demo Notebook for Less Annotating, More Classifying. Most helpful comments in the code came from the Demo Notebook. The credit for the code and most comments belongs to the authors of this paper: https://doi.org/10.1017/pan.2023.20.❗**\n","\n","Read more about the BERT-NLI approach used here: [\"Less Annotating, More Classifying: Addressing the Data Scarcity Issue of Supervised Machine Learning with Deep Transfer Learning and BERT-NLI\"](https://github.com/MoritzLaurer/less-annotating-with-bert-nli) by Moritz Laurer, Wouter van Atteveldt, Andreu Casas, Kasper Welbers.\n"],"metadata":{"id":"u0PsqLw0o0dS"}},{"cell_type":"markdown","source":["## Activate a GPU runtime"],"metadata":{"id":"bCzLYg11MctY"}},{"cell_type":"markdown","source":["In order to run this notebook on a GPU, click on \"Runtime\" > \"Change runtime type\" > select \"GPU\" in the menue bar in to top left. Training a Transformer is much faster on a GPU. Given Google's usage limits for GPUs, it is advisable to first test your non-training code on a CPU (Hardware accelerator \"None\" instead of GPU) and only use the GPU once you know that everything is working."],"metadata":{"id":"OZoAtCy_MhnU"}},{"cell_type":"markdown","source":["## Install relevant packages"],"metadata":{"id":"VOeUg4_YpxC7"}},{"cell_type":"code","source":["!pip install transformers[sentencepiece]==4.23\n","!pip install datasets==2.6\n","!pip install optuna==3.0"],"metadata":{"id":"qIjwLsME0KiW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Load general packages\n","# some more specialised packages are loaded in each sub section\n","import pandas as pd\n","import numpy as np\n","from google.colab.data_table import DataTable"],"metadata":{"id":"FT5nV1J3p4t5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive, files\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8I7Rh7FfNh6b","executionInfo":{"status":"ok","timestamp":1689243471314,"user_tz":-60,"elapsed":19022,"user":{"displayName":"Yara Kyrychenko","userId":"07690358214170724243"}},"outputId":"38f7e864-70a4-46bf-e640-10ad0c97baaa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# set random seed for reproducibility\n","SEED_GLOBAL = 42\n","np.random.seed(SEED_GLOBAL)"],"metadata":{"id":"WaGAh8DJwvKV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Download and prepare data"],"metadata":{"id":"8_DkNjuVo2iK"}},{"cell_type":"code","source":["df_train = pd.read_csv(\"/content/drive/MyDrive/ukraine/data-social-id/CSV FILE HERE\")"],"metadata":{"id":"QQWoy3Riji-l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_train.columns"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8ozMb3ZijuVM","executionInfo":{"status":"ok","timestamp":1689243472968,"user_tz":-60,"elapsed":7,"user":{"displayName":"Yara Kyrychenko","userId":"07690358214170724243"}},"outputId":"2b8bf940-8d21-4859-a1d2-816f4dfec9ea"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['Unnamed: 0', 'X', 'date', 'user_id', 'Zperiod', 'lang', 'source',\n","       'text', 'descUAid', 'descRUid', 'solUAid', 'hostRUid', 'hostUAid',\n","       'solRUid', 'Unnamed: 14'],\n","      dtype='object')"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0-SPaNcdogiu","executionInfo":{"status":"ok","timestamp":1689243474249,"user_tz":-60,"elapsed":1286,"user":{"displayName":"Yara Kyrychenko","userId":"07690358214170724243"}},"outputId":"c9f2fb48-3568-4afd-c2b6-e7ba67aedbfd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Length of training and test sets after sampling:  1600  (train)  400  (test).\n"]}],"source":["from sklearn.model_selection import train_test_split\n","sample_size = 2000\n","df_train, df_test = train_test_split(df_train[:sample_size], test_size=.2, random_state=SEED_GLOBAL,stratify=df_train['hostRUid'][:sample_size])\n","#note: because here we strarified the data by the training label the solidarity and hostility test sets are not the same\n","print(\"Length of training and test sets after sampling: \", len(df_train), \" (train) \", len(df_test), \" (test).\")"]},{"cell_type":"code","source":["df_train['label_text'] = df_train.hostRUid.apply(lambda x: 'Hostility towards Russia or Russians' if x else \"Other\")\n","df_test['label_text'] = df_test.hostRUid.apply(lambda x: 'Hostility towards Russia or Russians' if x else \"Other\")\n","df_train['label'] = df_train.hostRUid.apply(lambda x: 1 if x else 0)\n","df_test['label'] = df_test.hostRUid.apply(lambda x: 1 if x else 0)"],"metadata":{"id":"JZbAC4a3OKOY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#df_test.to_csv(\"/content/drive/MyDrive/ Exporting Hostility Test Set\")"],"metadata":{"id":"-eIrVyr1wiH6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## inspect the data\n","# label distribution train set\n","print(\"Train set label distribution: \", df_train.label_text.value_counts())\n","# label distribution test set\n","print(\"Test set label distribution: \", df_test.label_text.value_counts())\n","\n","# full training data table\n","DataTable(df_train, num_rows_per_page=5)\n","\n","#Train set label distribution:  Other                                   1290\n","#Hostility towards Russia or Russians     310\n","#Name: label_text, dtype: int64\n","#Test set label distribution:  Other                                   322\n","#Hostility towards Russia or Russians     78\n","#Name: label_text, dtype: int64"],"metadata":{"id":"Bk9yc_ppraUa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**If you want to run the notebook on your own dataset:**\n","\n","You can load your own training and test data above to fine-tune your own BERT-NLI model. Your own dataframe only needs two columns to be compatible with the code below: (1) a \"label_text\" column with the label texts of your classes, (2) a \"text_prepared\" column with the texts for training (you might need to delete/adapt the text preparation code cell below for your dataset)."],"metadata":{"id":"LvNpgSDGP47D"}},{"cell_type":"markdown","source":["## Create NLI hypotheses"],"metadata":{"id":"bRcsFtkQupNx"}},{"cell_type":"markdown","source":["**Formulate a hypothesis, which verbalises the classes/task you are interested in.**\n","\n","For this example, we base our task on the Manifesto Project codebook:  https://manifesto-project.wzb.eu/coding_schemes/mp_v4\n","\n","We store the hypothesis in a dictionary: The keys of the dictionary should be the names of the respective label from the training dataframe ('label_text' column); the values of the dictionary should be your manually formulated hypothesis linked to the respective labels."],"metadata":{"id":"Sk8nxKzGOqyW"}},{"cell_type":"code","source":["# dictionary mapping the dataset's label to manually formulated hypotheses based on the codebook\n","hypothesis_label_dic = {\n","    \"Other\": \"The quote is not about hostility towards Russia or Russians\",\n","    \"Hostility towards Russia or Russians\": \"The quote is expressing hostility, derogation or disliking of Russia or Russians, for example it criticises Russia, mentions Russians as incompetent, immoral people or the Russian Federation as a bad, weak or failing nation.\",\n","}"],"metadata":{"id":"zP9AUm_Uunw7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Prepare the input text**\n","\n","1.) We prepare the target texts by making them more naturally fit to the hypothesis. Here we simply wrap each target text into the string ' The quote: \"{target_text}\" - end of the quote. '\n","\n","2.) We surround the target text by its preceeding and following sentence. Adding context like this systematically increases performance.\n"],"metadata":{"id":"NKJb7sWwOy7h"}},{"cell_type":"code","source":["import re\n","df_train[\"text_prepared\"] = 'The quote: \"' + df_train.text.apply(lambda x: re.sub(r\"http\\S+\", \"<url>\", str(x)), 1) + '\" - end of the quote.'\n","df_test[\"text_prepared\"] =  'The quote: \"' +  df_test.text.apply(lambda x: re.sub(r\"http\\S+\", \"<url>\", str(x)), 1) + '\" - end of the quote.'\n"],"metadata":{"id":"cMdw-oZ9sCcS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Format the training and test datasets for NLI classification\n"],"metadata":{"id":"i37Rd6kUPH4m"}},{"cell_type":"markdown","source":["**Format the training data**\n","\n","1.) For each text with a specific class (label), the corresponding class-hypothesis needs to be added in the same row with the label 'true' (also expressed with the numeric label value 0).\n","\n","2.) Adding 'false' examples: The NLI task consists of predicting, whether a hypothesis is true or false given a context.\n","If we only give 'true' hypothesis-context pairs to the algorithm, it will not learn the 'false' class properly.\n","For each text, we therefore also add a row where the text is matched with a random wrong class label and give it the NLI label 'false' (also expressed with the numeric label value 1). This increases the training data by up to 2x.\n","\n","See the table below for the concrete format the training data takes after this pre-processing step.\n","Note that NLI can be formulated as a 3-class (entailment/neutral/contradiction) or 2-class (entailment/not-entailment) task. Both can be used here. We use the 2-class variant.\n","Note that the words entailment/neutral/contradition and true/neutral/false are used interchangably here. Both terminologies are used in the literature and coding instructions.\n"],"metadata":{"id":"YVX4o7ZgPG4Y"}},{"cell_type":"code","source":["## function for reformatting the train set\n","def format_nli_trainset(df_train=None, hypo_label_dic=None, random_seed=42):\n","  print(f\"Length of df_train before formatting step: {len(df_train)}.\")\n","  length_original_data_train = len(df_train)\n","\n","  df_train_lst = []\n","  for label_text, hypothesis in hypo_label_dic.items():\n","    ## entailment\n","    df_train_step = df_train[df_train.label_text == label_text].copy(deep=True)\n","    df_train_step[\"hypothesis\"] = [hypothesis] * len(df_train_step)\n","    df_train_step[\"label\"] = [0] * len(df_train_step)\n","    ## not_entailment\n","    df_train_step_not_entail = df_train[df_train.label_text != label_text].copy(deep=True)\n","    df_train_step_not_entail = df_train_step_not_entail.sample(n=min(len(df_train_step), len(df_train_step_not_entail)), random_state=random_seed)\n","    df_train_step_not_entail[\"hypothesis\"] = [hypothesis] * len(df_train_step_not_entail)\n","    df_train_step_not_entail[\"label\"] = [1] * len(df_train_step_not_entail)\n","    # append\n","    df_train_lst.append(pd.concat([df_train_step, df_train_step_not_entail]))\n","  df_train = pd.concat(df_train_lst)\n","\n","  # shuffle\n","  df_train = df_train.sample(frac=1, random_state=random_seed)\n","  df_train[\"label\"] = df_train.label.apply(int)\n","  df_train[\"label_nli_explicit\"] = [\"True\" if label == 0 else \"Not-True\" for label in df_train[\"label\"]]  # adding this just to simplify readibility\n","\n","  print(f\"After adding not_entailment training examples, the training data was augmented to {len(df_train)} texts.\")\n","  print(f\"Max augmentation could be: len(df_train) * 2 = {length_original_data_train*2}. It can also be lower, if there are more entail examples than not-entail for a majority class.\")\n","\n","  return df_train.copy(deep=True)\n","\n","\n","df_train_formatted = format_nli_trainset(df_train=df_train, hypo_label_dic=hypothesis_label_dic, random_seed=SEED_GLOBAL)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OkOD5cejttIV","executionInfo":{"status":"ok","timestamp":1684772176010,"user_tz":-60,"elapsed":202,"user":{"displayName":"Yara Kyrychenko","userId":"07690358214170724243"}},"outputId":"16eb2e23-6536-438e-bd5b-f10b848d59ed"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Length of df_train before formatting step: 1600.\n","After adding not_entailment training examples, the training data was augmented to 2220 texts.\n","Max augmentation could be: len(df_train) * 2 = 3200. It can also be lower, if there are more entail examples than not-entail for a majority class.\n"]}]},{"cell_type":"markdown","source":["**Inspect reformatted training dataset**\n","\n","Label 0 means that the hypothesis is 'true', label 1 means that the hypothesis is 'not-true'.\n"],"metadata":{"id":"TUBG4XHpQWgT"}},{"cell_type":"code","source":["DataTable(df_train_formatted[[\"label\", \"label_nli_explicit\", \"hypothesis\", \"text_prepared\"]], num_rows_per_page=5)"],"metadata":{"id":"axnUFc0u5DcE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Format the test set**\n","\n","To know which class-hypothesis is true for a specific text, we need to test every possible class-hypothesis for each text. We therefore multiple the rows/texts in the test set by the number of hypothesis and pair each text with all possible hypotheses. The table below shows what the reformatted test set looks like."],"metadata":{"id":"o7v0j8GPQifE"}},{"cell_type":"code","source":["## function for reformatting the test set\n","def format_nli_testset(df_test=None, hypo_label_dic=None):\n","  ## explode test dataset for N hypotheses\n","  hypothesis_lst = [value for key, value in hypo_label_dic.items()]\n","  print(\"Number of hypotheses/classes: \", len(hypothesis_lst))\n","\n","  # label lists with 0 at alphabetical position of their true hypo, 1 for not-true hypos\n","  label_text_label_dic_explode = {}\n","  for key, value in hypo_label_dic.items():\n","    label_lst = [0 if value == hypo else 1 for hypo in hypothesis_lst]\n","    label_text_label_dic_explode[key] = label_lst\n","\n","  df_test[\"label\"] = df_test.label_text.map(label_text_label_dic_explode)\n","  df_test[\"hypothesis\"] = [hypothesis_lst] * len(df_test)\n","  print(f\"Original test set size: {len(df_test)}\")\n","\n","  # explode dataset to have K-1 additional rows with not_entail label and K-1 other hypotheses\n","  # ! after exploding, cannot sample anymore, because distorts the order to true label values, which needs to be preserved for evaluation code\n","  df_test = df_test.explode([\"hypothesis\", \"label\"])  # multi-column explode requires pd.__version__ >= '1.3.0'\n","  print(f\"Test set size for NLI classification: {len(df_test)}\\n\")\n","\n","  df_test[\"label_nli_explicit\"] = [\"True\" if label == 0 else \"Not-True\" for label in df_test[\"label\"]]  # adding this just to simplify readibility\n","\n","  return df_test.copy(deep=True)\n","\n","\n","df_test_formatted = format_nli_testset(df_test=df_test, hypo_label_dic=hypothesis_label_dic)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cx3N-qQR5BFl","executionInfo":{"status":"ok","timestamp":1684772183632,"user_tz":-60,"elapsed":284,"user":{"displayName":"Yara Kyrychenko","userId":"07690358214170724243"}},"outputId":"294a8957-c7c9-4eff-80a2-9ba98e71ae53"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of hypotheses/classes:  2\n","Original test set size: 400\n","Test set size for NLI classification: 800\n","\n"]}]},{"cell_type":"markdown","source":["**Inspect the reformatted test dataset**\n"],"metadata":{"id":"aYpd2-3MQ2Ky"}},{"cell_type":"code","source":["DataTable(df_test_formatted[[\"label\", \"label_nli_explicit\", \"hypothesis\", \"text_prepared\"]].sort_values([\"text_prepared\", \"hypothesis\"]), num_rows_per_page=6, max_rows=10_000)"],"metadata":{"id":"5umzYbAz7v6Q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Fine-tuning"],"metadata":{"id":"G_PCMiyIw7mf"}},{"cell_type":"markdown","source":["We use [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) for loading and training our model. They provide great documentation and also a very good [course](https://huggingface.co/course/chapter1/1) on how to use Transformers."],"metadata":{"id":"17a2ENVfVZQU"}},{"cell_type":"markdown","source":["**Loading an NLI model**\n","\n","You can can use any NLI model on the Hugging Face Hub. For normal English use-cases, we recommend this [base-size model](https://huggingface.co/MoritzLaurer/DeBERTa-v3-base-mnli-fever-docnli-ling-2c); for multilingual/non-English use-cases, we recommend this [multilingual model](https://huggingface.co/MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7); for best performance in English (but high compute and memory requirements) we recommend this [large model](https://huggingface.co/MoritzLaurer/DeBERTa-v3-large-mnli-fever-anli-ling-wanli).\n"],"metadata":{"id":"l8Z3f3TtRCaJ"}},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","import torch\n","\n","## load the BERT-NLI model and its tokenizer\n","# you can choose any of the NLI models here: https://huggingface.co/MoritzLaurer\n","model_name = \"MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True, model_max_length=512)\n","model = AutoModelForSequenceClassification.from_pretrained(model_name)\n","\n","# use GPU (cuda) if available, otherwise use CPU\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(f\"Device: {device}\")\n","model.to(device);\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":258,"referenced_widgets":["d3c4e155b9674147bb0dfe0d27317d73","d3ea5527da7145289d341539f058f84d","8cb02ce6efab4a93904e3764e149af70","db9f5b1633894ad3b7b50cac1485be64","dc21f2fe7b2b4772b4e804548e470b34","96892d420d454f48b80e773e41aceead","0f03416fe3fc4d8bb80f818943017004","377c5de7fcc8428bb60b8edf7ba64030","a3bac4b449574337b16b6d5668668322","44b89ec419974d729089fe6cfe7febf8","40389029c595408593c75f9c0279d659","72946a7f14a44568a39db3d3535f0069","4b5b00c052aa407b8a44978154a52c7d","ef5b135b3dd44b66877f6023708aba2c","3df1e745b8ff426793b95d1a166da592","bf9f0968ecf94237bfe2003b9a15eb6b","8d5643c9d2d44e3f8dca5b7fe6526d45","4f338671547844f0ab29d7f56aacdedd","787f3e19fc4743d39227a271e3c554a2","f7b2d4652234473a884214279949307d","e810fe91cf4c4a6db464f513278b8a9b","9104eff747e34d19b82556f224ce45e5","4032e6a4ced44536b51128718fadc545","e9e9bdf7fba94c6c9ffcabec8623b5df","78590a4552a1407f854b68b00e2fba36","592b1ce982364ecfa577ff59d1b87ec2","f4f39c9872ac450fa6b732606b4c890e","9982d37549284eec99a13b9d55af72ee","56e0673586114570a396d8bae70e0429","7126fa67c0754d61b6b0839e9094e99d","8c7ea93a1e40459e934410ad8a004c4e","512210131d1941849cb15f79fae08329","543d49cf129941e6b91f1ea1ea8002ce","2be9fee833004d9f9facaaa31c50d485","1076dd647a4c4adbbf69c4fafd822b0f","f7c9ae27a4054809977178df56472d84","23ae5ae1648a4415b7f29850391d58ee","532f548ace934b9c9d6288885063096a","4052feb7c34748fea09b6e8454fa5f33","7825f37f54084907868d2297eaae558d","870f9fc0ad3145d78db9e5d5d0987fb4","8e3434dc62da4ad2bb002469343ff7fc","ad5fc0ed2ee740ac8deebd34711426d5","3167b40fa71f4ab8a987e70cfbd538c3","a3570d2b59fa4d079c8284a7783affed","668ef27d364249f8bedc3ba5aa4082ca","fe74659f7449485aa94f5f37bdff0400","547e4589d8334dccbad71cbe3eb4e087","2e8d8f2ba2f049d48019be72ac648287","ea3fcacd70e64675b7896ab3ee172f2d","98835fad94ee4464bbb640f9580c0b61","92a61437427f44a0b3369b2cb78467fb","5b47ad85fc354b0caa4e111bf5828cc2","4fb8bd5f61024243bac7d4feff186fd3","b2af99791472490ea2e1645da1252e47","94a1d5cb1c8a438ba7d8774459946ed8","ea72dd515ecb45b0863fbf3670031769","fa0d7d1aa4594c6bbb71a70191fcfe1f","929326ec85364a65973a408c47ea5152","6d53ea949469425ca7cfe414d335579a","785804d02ac147e2873dcb39a17a812c","da500e48711842769edab63d7b52191e","34dd8ff2555d41fcb1b4ab6d591da849","4bcde223b2c945ee89bcbe7a60d1d4ef","8c1cf07d021441d3bfaa534e0f9d4293","d93f0f360b07430a8b3597a84d2deddd","f29f69d00dcb4f399be3e14db2de1740","66b75869c6a44caf978e802c8a646144","5cda777958c7483d9b8b0d64394a349a","e5496521b0fe4dd0b62e9174b88e3552","c85d0f5661fa4f31bbe56e0a9421cd48","cda13ee8d7ce4a208c3915d3ed904558","e7f0bb04762f40e38ee89709353d389e","7daf6faf49804b9391cf25b24129d5df","9ba06cd560604193900982934656da98","5b401d8bdce746d7b969e6895f6add5c","eadbc44518994e75a5ea64755b4747b0"]},"id":"yC4VuOspw9cW","executionInfo":{"status":"ok","timestamp":1684772212994,"user_tz":-60,"elapsed":17758,"user":{"displayName":"Yara Kyrychenko","userId":"07690358214170724243"}},"outputId":"c2d45d78-1681-494a-95dd-88cf526ab137"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/467 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3c4e155b9674147bb0dfe0d27317d73"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading spm.model:   0%|          | 0.00/4.31M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72946a7f14a44568a39db3d3535f0069"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading tokenizer.json:   0%|          | 0.00/16.3M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4032e6a4ced44536b51128718fadc545"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)in/added_tokens.json:   0%|          | 0.00/23.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2be9fee833004d9f9facaaa31c50d485"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)cial_tokens_map.json:   0%|          | 0.00/173 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3570d2b59fa4d079c8284a7783affed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/1.09k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94a1d5cb1c8a438ba7d8774459946ed8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/558M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f29f69d00dcb4f399be3e14db2de1740"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Device: cuda\n"]}]},{"cell_type":"markdown","source":["**Tokenize data**"],"metadata":{"id":"Y2qMjRt2SRMc"}},{"cell_type":"code","source":["# convert pandas dataframes to Hugging Face dataset object to facilitate pre-processing\n","import datasets\n","\n","dataset = datasets.DatasetDict({\n","    \"train\": datasets.Dataset.from_pandas(df_train_formatted),\n","    \"test\": datasets.Dataset.from_pandas(df_test_formatted)\n","})\n","\n","# tokenize\n","def tokenize_nli_format(examples):\n","  return tokenizer(examples[\"text_prepared\"], examples[\"hypothesis\"], truncation=True, max_length=512)  #512 max_length can be reduced to e.g. 256 to increase speed, but long texts will be cut off\n","dataset[\"train\"] = dataset[\"train\"].map(tokenize_nli_format, batched=True)\n","dataset[\"test\"] = dataset[\"test\"].map(tokenize_nli_format, batched=True)\n","\n","# remove unnecessary columns for model training\n","\n","dataset = dataset.remove_columns(['label_text','Unnamed: 0', 'X', 'date', 'text', 'user_id','Zperiod', 'lang', 'source','descUAid', 'descRUid', 'solUAid', 'hostRUid', 'hostUAid',\n","       'solRUid', 'Unnamed: 14', '__index_level_0__'])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["0e38879956e14dcdbbee23802bfd7dcf","8c32fc01be9c42b2b2cbb094a09f5b7a","093c102538664c4ea40ef5e7146c21ca","4644a9e6e89141dfad120c3f700b31be","3728ddd607984b38bae8d5e1ac518c8c","2abe4417632d465484830374534dd12e","98caa2c3e6724a96abe6ae38d361b79f","3eb7ac36ec1d4f8582b451f34cfd9179","d37f75af80834b7ba8c0085e5269e739","914205e2d3df48339251865558ffa288","2177973e7a7b4c3ba28d62809ae3d291","049003993aec40f3ade2bb0610f30b0f","68982a5d5dee4fd198e0dd0205cb8d14","8a3f0775cc4a421b8078894cdce4113e","23e4cd6f159a42308a0760e68825717d","12f3e981af3a49e78a929e1f7b28b834","093d7ac6b0e043329bedbdd505800318","cb30854187a44c04b560065c0f3ddba6","c2d4b37c056d4147bd9e43a0ff6b728c","7d67969b989a4077a3c8226d1083ee27","0ed066fa4b8f4a14a4a55f00a6515b7c","d58f9216bad54501bc566910f47e894a"]},"id":"nyvO3Xr01NmR","executionInfo":{"status":"ok","timestamp":1684772218284,"user_tz":-60,"elapsed":1250,"user":{"displayName":"Yara Kyrychenko","userId":"07690358214170724243"}},"outputId":"4b9aaff5-da85-46a6-f69c-16d20536c958"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/3 [00:00<?, ?ba/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e38879956e14dcdbbee23802bfd7dcf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"049003993aec40f3ade2bb0610f30b0f"}},"metadata":{}}]},{"cell_type":"markdown","source":["**Inspect processed data**"],"metadata":{"id":"XMSuf_2BSwE2"}},{"cell_type":"code","source":["print(\"The overall structure of the pre-processed train and test sets:\\n\")\n","print(dataset)\n","\n","print(\"\\n\\nAn example for a tokenized hypothesis-context pair:\\n\")\n","print(dataset[\"train\"][0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dtVbrtfx4Bke","executionInfo":{"status":"ok","timestamp":1684772220659,"user_tz":-60,"elapsed":327,"user":{"displayName":"Yara Kyrychenko","userId":"07690358214170724243"}},"outputId":"94e04a54-91c6-42b2-f5fe-4219f3f1cf0f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The overall structure of the pre-processed train and test sets:\n","\n","DatasetDict({\n","    train: Dataset({\n","        features: ['label', 'text_prepared', 'hypothesis', 'label_nli_explicit', 'input_ids', 'token_type_ids', 'attention_mask'],\n","        num_rows: 2220\n","    })\n","    test: Dataset({\n","        features: ['label', 'text_prepared', 'hypothesis', 'label_nli_explicit', 'input_ids', 'token_type_ids', 'attention_mask'],\n","        num_rows: 800\n","    })\n","})\n","\n","\n","An example for a tokenized hypothesis-context pair:\n","\n","{'label': 1, 'text_prepared': 'The quote: \"У ОК \"Південь\" розповіли про наявність можливостей щодо знищення окупантів<url>\" - end of the quote.', 'hypothesis': 'The quote is not about hostility towards Russia or Russians', 'label_nli_explicit': 'Not-True', 'input_ids': [1, 487, 66640, 268, 314, 3901, 260, 44769, 314, 3252, 1078, 68136, 312, 51307, 123058, 924, 260, 1966, 98453, 260, 44847, 39792, 1497, 4023, 260, 40318, 36476, 59340, 11967, 1078, 2710, 1475, 670, 312, 260, 265, 3163, 305, 288, 66640, 261, 2, 487, 66640, 340, 777, 1389, 6308, 179960, 289, 19079, 25411, 632, 26797, 264, 2], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"]}]},{"cell_type":"markdown","source":["### Setting training arguments / hyperparameters"],"metadata":{"id":"mYAPVubATCCM"}},{"cell_type":"markdown","source":["The following cell sets several important hyperparameters. We chose parameters that work well in general to avoid the need for hyperparameter search. Further below, we also provide code for hyperparameter search, if researchers want to try to increase performance by a few percentage points."],"metadata":{"id":"ylyp52i6T-NG"}},{"cell_type":"code","source":["from transformers import TrainingArguments, Trainer, logging\n","\n","# Set the directory to write the fine-tuned model and training logs to.\n","# With google colab, this will create a temporary folder, which will be deleted once you disconnect.\n","# You can connect to your personal google drive to save models and logs properly.\n","training_directory = \"BERT-nli-ua-host\"\n","\n","# FP16 is a hyperparameter which can increase training speed and reduce memory consumption, but only on GPU and if batch-size > 8, see here: https://huggingface.co/transformers/performance.html?#fp16\n","# FP16 does not work on CPU or for multilingual mDeBERTa models\n","fp16_bool = True if torch.cuda.is_available() else False\n","if \"mdeberta\" in model_name.lower(): fp16_bool = False  # multilingual mDeBERTa does not support FP16 yet: https://github.com/microsoft/DeBERTa/issues/77\n","# in case of hyperparameter search end the end: FP16 has to be set to False. The integrated hyperparameter search with the Hugging Face Trainer can lead to errors otherwise.\n","fp16_bool = False\n","\n","# Hugging Face tipps to increase training speed and decrease out-of-memory (OOM) issues: https://huggingface.co/transformers/performance.html?\n","# Overview of all training arguments: https://huggingface.co/transformers/main_classes/trainer.html#transformers.TrainingArguments\n","train_args = TrainingArguments(\n","    output_dir=f'./results/{training_directory}',\n","    logging_dir=f'./logs/{training_directory}',\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=8,  # if you get an out-of-memory error, reduce this value to 8 or 4 and restart the runtime. Higher values increase training speed, but also increase memory requirements. Ideal values here are always a multiple of 8.\n","    per_device_eval_batch_size=32,  # if you get an out-of-memory error, reduce this value, e.g. to 40 and restart the runtime\n","    #gradient_accumulation_steps=4, # Can be used in case of memory problems to reduce effective batch size. accumulates gradients over X steps, only then backward/update. decreases memory usage, but also slightly speed. (!adapt/halve batch size accordingly)\n","    num_train_epochs=10,  # this can be increased, but higher values increase training time. Good values for NLI are between 3 and 20.\n","    warmup_ratio=0.25,  # a good normal default value is 0.06 for normal BERT-base models, but since we want to reuse prior NLI knowledge and avoid catastrophic forgetting, we set the value higher\n","    weight_decay=0.1,\n","    seed=SEED_GLOBAL,\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"accuracy\",\n","    fp16=fp16_bool,  # Can speed up training and reduce memory consumption, but only makes sense at batch-size > 8. loads two copies of model weights, which creates overhead. https://huggingface.co/transformers/performance.html?#fp16\n","    fp16_full_eval=fp16_bool,\n","    evaluation_strategy=\"no\", # options: \"no\"/\"steps\"/\"epoch\"\n","    #eval_steps=10_000,  # evaluate after n steps if evaluation_strategy!='steps'. defaults to logging_steps\n","    save_strategy = \"no\",  # options: \"no\"/\"steps\"/\"epoch\"\n","    #save_steps=10_000,              # Number of updates steps before two checkpoint saves.\n","    #save_total_limit=10,             # If a value is passed, will limit the total amount of checkpoints. Deletes the older checkpoints in output_dir\n","    #logging_strategy=\"steps\",\n","    report_to=\"all\",  # \"all\"  # logging\n","    #push_to_hub=False,\n","    #push_to_hub_model_id=f\"{model_name}-finetuned-{task}\",\n",")\n"],"metadata":{"id":"M4bWptLg4qin"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# helper function to clean memory and reduce risk of out-of-memory error\n","import gc\n","def clean_memory():\n","  #del(model)\n","  if torch.cuda.is_available():\n","    torch.cuda.empty_cache()\n","    torch.cuda.ipc_collect()\n","  gc.collect()\n","\n","clean_memory()"],"metadata":{"id":"LFi3c22L7ahu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Custom function to compute metrics for NLI\n","\n","We multiplied each text N times for each class in the test set and NLI can only predict 2 or 3 classes: true/not-true or true/neutral/false. This means that we cannot use standard functions for computing metrics. The following function reformats the model's output in a way that allows for the calculation of standard metrics like accuracy, F1-macro etc."],"metadata":{"id":"a5hnIwQeUmfq"}},{"cell_type":"code","source":["from sklearn.metrics import balanced_accuracy_score, precision_recall_fscore_support, accuracy_score, classification_report\n","\n","def compute_metrics_nli_binary(eval_pred, label_text_alphabetical=None):\n","    predictions, labels = eval_pred\n","\n","    ### reformat model output to enable calculation of standard metrics\n","    # split in chunks with predictions for each hypothesis for one unique premise\n","    def chunks(lst, n):  # Yield successive n-sized chunks from lst. https://stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks\n","        for i in range(0, len(lst), n):\n","            yield lst[i:i + n]\n","\n","    # for each chunk/premise, select the most likely hypothesis\n","    softmax = torch.nn.Softmax(dim=1)\n","    prediction_chunks_lst = list(chunks(predictions, len(set(label_text_alphabetical)) ))\n","    hypo_position_highest_prob = []\n","    for i, chunk in enumerate(prediction_chunks_lst):\n","        hypo_position_highest_prob.append(np.argmax(np.array(chunk)[:, 0]))  # only accesses the first column of the array, i.e. the entailment/true prediction logit of all hypos and takes the highest one\n","\n","    label_chunks_lst = list(chunks(labels, len(set(label_text_alphabetical)) ))\n","    label_position_gold = []\n","    for chunk in label_chunks_lst:\n","        label_position_gold.append(np.argmin(chunk))  # argmin to detect the position of the 0 among the 1s\n","\n","    print(\"Highest probability prediction per premise: \", hypo_position_highest_prob)\n","    print(\"Correct label per premise: \", label_position_gold)\n","\n","    ### calculate standard metrics\n","    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(label_position_gold, hypo_position_highest_prob, average='macro')  # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html\n","    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(label_position_gold, hypo_position_highest_prob, average='micro')  # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html\n","    acc_balanced = balanced_accuracy_score(label_position_gold, hypo_position_highest_prob)\n","    acc_not_balanced = accuracy_score(label_position_gold, hypo_position_highest_prob)\n","    metrics = {'f1_macro': f1_macro,\n","               'f1_micro': f1_micro,\n","               'accuracy_balanced': acc_balanced,\n","               'accuracy_not_b': acc_not_balanced,\n","               #'precision_macro': precision_macro,\n","               #'recall_macro': recall_macro,\n","               #'precision_micro': precision_micro,\n","               #'recall_micro': recall_micro,\n","               #'label_gold_raw': label_position_gold,\n","               #'label_predicted_raw': hypo_position_highest_prob\n","               }\n","    print(\"Aggregate metrics: \", {key: metrics[key] for key in metrics if key not in [\"label_gold_raw\", \"label_predicted_raw\"]} )  # print metrics but without label lists\n","    print(\"Detailed metrics: \", classification_report(label_position_gold, hypo_position_highest_prob, labels=np.sort(pd.factorize(label_text_alphabetical, sort=True)[0]), target_names=label_text_alphabetical, sample_weight=None, digits=2, output_dict=True,\n","                                zero_division='warn'), \"\\n\")\n","    return metrics\n","\n","# Create alphabetically ordered list of the original dataset classes/labels\n","# This is necessary to be sure that the ordering of the test set labels and predictions is the same. Otherwise there is a risk that labels and predictions are in a different order and resulting metrics are wrong.\n","label_text_alphabetical = np.sort(df_train.label_text.unique())\n"],"metadata":{"id":"lcXPQ25F77gG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Fine-tuning and evaluation  (IGNORE THIS AND PROCEED TO HP SEARCH)"],"metadata":{"id":"06NpYcJtVz7O"}},{"cell_type":"markdown","source":["Let's start fine-tuning the model!\n","\n","If you get an 'out-of-memory' error, reduce the 'per_device_train_batch_size' to 8 or 4 in the TrainingArguments above and restart the runtime. If you don't restart your runtime (menu to the to left 'Runtime' > 'Restart runtime') and rerun the entire script, the 'out-of-memory' error will probably not go away."],"metadata":{"id":"DYLN5SaWXVOH"}},{"cell_type":"code","source":["# training\n","trainer = Trainer(\n","    model=model,\n","    tokenizer=tokenizer,\n","    args=train_args,\n","    train_dataset=dataset[\"train\"],  #.shard(index=1, num_shards=100),  # could shard data for faster testing https://huggingface.co/docs/datasets/processing.html#sharding-the-dataset-shard\n","    eval_dataset=dataset[\"test\"],  #.shard(index=1, num_shards=100),\n","    compute_metrics=lambda eval_pred: compute_metrics_nli_binary(eval_pred, label_text_alphabetical=label_text_alphabetical)\n",")\n","\n","trainer.train()\n"],"metadata":{"id":"w2PIfFvKVmlp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Evaluate the fine-tuned model on the held-out test set\n","results = trainer.evaluate()"],"metadata":{"id":"tgXO927fVmlq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(results)"],"metadata":{"id":"EWnKnsfVBnvu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Hyperparameter Search"],"metadata":{"id":"qkTjWn2VVZ9g"}},{"cell_type":"markdown","source":["To increase performance, you can also conduct a hyperparameter search (hp-search), to try and find the best hyperparameters for your specific task and dataset. The trade-off is that hp-search is very compute intensive, but finding better hyperparameters for your task can increase performance. Make sure to conduct hp-search on a sub-set of the training set (i.e. validation set) and not the final test set to avoid data leakage of the test set before final testing.\n","\n","Note that for small datasets, running the hp-search only on one train-validation split is not ideal. For datasets with less than around 2000 training data points, we recommend running the hp-search on two different random train-validation split. We implemented this for our paper, but not in this notebook as this would make the code harder to understand.\n","\n","Documentation with more information on hp-search with Hugging Face Transformers is available [here](https://huggingface.co/docs/transformers/main/hpo_train)."],"metadata":{"id":"9TUHQYU2WKkQ"}},{"cell_type":"code","source":["## train-validation split - test set should not be visible during hp-search\n","# https://huggingface.co/docs/datasets/v2.5.1/en/package_reference/main_classes#datasets.Dataset.train_test_split\n","\n","# the ideal size of the validation set depends on the size of your training data. Each label should have at the very least a few dozen examples in the validation set (ideally several hundred)\n","validation_set_size = 0.4  # for a training data size of 1000 with 3 classes we use 40% of the training data for validating hyperparameters\n","\n","# reformatting of label column to enable dataset stratification\n","from datasets import ClassLabel\n","new_features = dataset[\"train\"].features.copy()\n","if len(model.config.label2id.keys()) == 2:  # for 2-class NLI model\n","  label_names = [\"entailment\", \"not-entailment\"]\n","elif len(model.config.label2id.keys()) == 3:  # for 3-class NLI model\n","  label_names = [\"entailment\", \"neutral\", \"contradiction\"]\n","new_features['label'] = ClassLabel(names=label_names)\n","print(len(dataset['train']))\n","dataset = dataset.cast(new_features)\n","print(len(dataset['train']))\n","\n","# train-validation split for hp-search\n","dataset_hp = dataset[\"train\"].train_test_split(test_size=validation_set_size, seed=SEED_GLOBAL, shuffle=True, stratify_by_column=\"label\")\n","print(dataset_hp)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":289,"referenced_widgets":["ad8c2d75866a4828904cc1f95e5f4143","2cc7cf13e1e244dc82659f89e806f46b","2afd469f38184b3aaec858ef59e2c8e1","4ddc96ba65324a85a260548cc09e0128","4306cc94287d4fccaac63a7684f8146f","0f4e580d654546c8b411101da1d40e50","fa17249c28d649d1ad9a8de752230cf3","2ffbb43b63d44ffd88b7c9ae27fed265","e678c6640f634ed1b56078a8b11bffc2","64d91991852b43adaa9e3ec5c55e70d5","8e70198a56c344548254f02f297ea3d9","47d561ab7bd9432794f1b702dd97b5a4","0e7a44c50ba1407aae35deb92788513a","dce2131f5ccb4506a65e340a02186547","66a76081ea1d4f5780e2b38df661164d","177506cd9e3c46018af39a37c2a9bac5","b5506a3947394707a00ccb0d0b720088","ce9b371b7f8f4c4e9b17b8c4b297cdea","ec60d37faa6e41bc832f93b487c4a72f","a2b599365e9e401190ef7ce4089616c8","ba008df7455e4de781da40c70c0deaf7","47891fd76d094e7faf4cf4e576af04fc"]},"id":"_igmvJD2YSYO","executionInfo":{"status":"ok","timestamp":1684772245925,"user_tz":-60,"elapsed":551,"user":{"displayName":"Yara Kyrychenko","userId":"07690358214170724243"}},"outputId":"39af3150-64a7-4827-b1dc-d58b2ee365d2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2220\n"]},{"output_type":"display_data","data":{"text/plain":["Casting the dataset:   0%|          | 0/1 [00:00<?, ?ba/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad8c2d75866a4828904cc1f95e5f4143"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Casting the dataset:   0%|          | 0/1 [00:00<?, ?ba/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47d561ab7bd9432794f1b702dd97b5a4"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["1000\n","DatasetDict({\n","    train: Dataset({\n","        features: ['label', 'text_prepared', 'hypothesis', 'label_nli_explicit', 'input_ids', 'token_type_ids', 'attention_mask'],\n","        num_rows: 600\n","    })\n","    test: Dataset({\n","        features: ['label', 'text_prepared', 'hypothesis', 'label_nli_explicit', 'input_ids', 'token_type_ids', 'attention_mask'],\n","        num_rows: 400\n","    })\n","})\n"]}]},{"cell_type":"code","source":["## Reinitialize trainer for hp-search\n","# https://discuss.huggingface.co/t/using-hyperparameter-search-in-trainer/785/10\n","\n","def model_init():\n","  clean_memory()\n","  return AutoModelForSequenceClassification.from_pretrained(model_name).to(device)  # return_dict=True\n","\n","trainer = Trainer(\n","    model_init=model_init,\n","    tokenizer=tokenizer,\n","    args=train_args,\n","    train_dataset=dataset_hp[\"train\"],\n","    eval_dataset=dataset_hp[\"test\"],\n","    compute_metrics=lambda eval_pred: compute_metrics_nli_binary(eval_pred, label_text_alphabetical=label_text_alphabetical)\n",");\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aX31mUPb7r6C","executionInfo":{"status":"ok","timestamp":1684772262974,"user_tz":-60,"elapsed":3830,"user":{"displayName":"Yara Kyrychenko","userId":"07690358214170724243"}},"outputId":"cec56997-3b9f-4a10-9489-cd72b5cf2c0a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--MoritzLaurer--mDeBERTa-v3-base-xnli-multilingual-nli-2mil7/snapshots/12dfea2a0b9ea8019b809105d4f62ffec7af622c/config.json\n","Model config DebertaV2Config {\n","  \"_name_or_path\": \"MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7\",\n","  \"architectures\": [\n","    \"DebertaV2ForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"entailment\",\n","    \"1\": \"neutral\",\n","    \"2\": \"contradiction\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"contradiction\": 2,\n","    \"entailment\": 0,\n","    \"neutral\": 1\n","  },\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"torch_dtype\": \"float16\",\n","  \"transformers_version\": \"4.23.0\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 251000\n","}\n","\n","loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--MoritzLaurer--mDeBERTa-v3-base-xnli-multilingual-nli-2mil7/snapshots/12dfea2a0b9ea8019b809105d4f62ffec7af622c/pytorch_model.bin\n","All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n","\n","All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n"]}]},{"cell_type":"markdown","source":["**Define the hyperparameters you want to optimise**\n","\n","For a detailed discussion of different hyperparameters, see the appendix of our paper."],"metadata":{"id":"_AL-t2KBeMqM"}},{"cell_type":"code","source":["# we use Optuna for hp-search: https://optuna.readthedocs.io/en/stable/\n","def my_hp_space(trial):\n","    return {\n","        \"learning_rate\": trial.suggest_categorical(\"learning_rate\", [9e-6, 2e-5, 4e-5]),\n","        \"num_train_epochs\": trial.suggest_int(\"num_train_epochs\", 4, 16, log=False, step=2),   # increasing the maximum number of epochs here could increase performance but will take (much) longer to train\n","        \"warmup_ratio\": trial.suggest_float(\"warmup_ratio\", 0.1, 0.6, log=True),\n","        \"per_device_train_batch_size\": 8,  # lower this value in case of out-of-memory errors and restart the runtime\n","        #\"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [8, 16, 32]),\n","    }\n"],"metadata":{"id":"LqIHNkWFahaD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Run HP search!**\n","\n","Choose the number of hyperparameter configurations you want to test. In our experiments we found that after 10 to 15 trials with around 4 hyperparameters, performance is unlikely to increase meaningfully. 15 trials seems to be a safe value, but can take a while to run."],"metadata":{"id":"3vo_UH43d9yB"}},{"cell_type":"code","source":["import optuna\n","\n","# number of differen hp configurations to test\n","numer_of_trials = 16  # increasing this value can lead to better hyperparameters, but will take longer\n","# chose the sampler for sampling hp configurations\n","optuna_sampler = optuna.samplers.TPESampler(seed=SEED_GLOBAL, consider_prior=True, prior_weight=1.0, consider_magic_clip=True, consider_endpoints=False, n_startup_trials=numer_of_trials/2, n_ei_candidates=24, multivariate=False, group=False, warn_independent_sampling=True, constant_liar=False)  # https://optuna.readthedocs.io/en/stable/reference/generated/optuna.samplers.TPESampler.html#optuna.samplers.TPESampler\n","\n","# Hugging Face Documentation: https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer.hyperparameter_search\n","best_run = trainer.hyperparameter_search(\n","    n_trials=numer_of_trials,\n","    direction=\"maximize\",\n","    hp_space=my_hp_space,\n","    backend='optuna',\n","    **{\"sampler\": optuna_sampler}\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"B0gvfJ9xGuM3","outputId":"7b8dad10-29d5-413c-adca-d4792e849fff","executionInfo":{"status":"ok","timestamp":1684777520205,"user_tz":-60,"elapsed":5252994,"user":{"displayName":"Yara Kyrychenko","userId":"07690358214170724243"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[32m[I 2023-05-22 16:17:48,626]\u001b[0m A new study created in memory with name: no-name-2211e31d-34ba-4a89-aead-be33cc6d498d\u001b[0m\n","Trial: {'learning_rate': 2e-05, 'num_train_epochs': 12, 'warmup_ratio': 0.13225317293225414}\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--MoritzLaurer--mDeBERTa-v3-base-xnli-multilingual-nli-2mil7/snapshots/12dfea2a0b9ea8019b809105d4f62ffec7af622c/config.json\n","Model config DebertaV2Config {\n","  \"_name_or_path\": \"MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7\",\n","  \"architectures\": [\n","    \"DebertaV2ForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"entailment\",\n","    \"1\": \"neutral\",\n","    \"2\": \"contradiction\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"contradiction\": 2,\n","    \"entailment\": 0,\n","    \"neutral\": 1\n","  },\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"torch_dtype\": \"float16\",\n","  \"transformers_version\": \"4.23.0\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 251000\n","}\n","\n","loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--MoritzLaurer--mDeBERTa-v3-base-xnli-multilingual-nli-2mil7/snapshots/12dfea2a0b9ea8019b809105d4f62ffec7af622c/pytorch_model.bin\n","All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n","\n","All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n","The following columns in the training set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: hypothesis, label_nli_explicit, text_prepared. If hypothesis, label_nli_explicit, text_prepared are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 600\n","  Num Epochs = 12\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 900\n","You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","/usr/local/lib/python3.10/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:745: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  attention_scores = torch.bmm(query_layer, key_layer.transpose(-1, -2)) / torch.tensor(\n","/usr/local/lib/python3.10/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:829: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  score += c2p_att / torch.tensor(scale, dtype=c2p_att.dtype)\n","/usr/local/lib/python3.10/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:852: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  score += p2c_att / torch.tensor(scale, dtype=p2c_att.dtype)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='900' max='900' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [900/900 05:55, Epoch 12/12]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.267200</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: hypothesis, label_nli_explicit, text_prepared. If hypothesis, label_nli_explicit, text_prepared are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 400\n","  Batch size = 32\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='208' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [13/13 1:21:29]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[32m[I 2023-05-22 16:23:58,272]\u001b[0m Trial 0 finished with value: 2.796157877706835 and parameters: {'learning_rate': 2e-05, 'num_train_epochs': 12, 'warmup_ratio': 0.13225317293225414}. Best is trial 0 with value: 2.796157877706835.\u001b[0m\n","Trial: {'learning_rate': 4e-05, 'num_train_epochs': 12, 'warmup_ratio': 0.3556211334079358}\n"]},{"output_type":"stream","name":"stdout","text":["Highest probability prediction per premise:  [1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0]\n","Correct label per premise:  [0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n","Aggregate metrics:  {'f1_macro': 0.6395777911267485, 'f1_micro': 0.685, 'accuracy_balanced': 0.7865800865800865, 'accuracy_not_b': 0.685}\n","Detailed metrics:  {'Hostility towards Russia or Russians': {'precision': 0.9811320754716981, 'recall': 0.6303030303030303, 'f1-score': 0.7675276752767528, 'support': 165}, 'Other': {'precision': 0.35106382978723405, 'recall': 0.9428571428571428, 'f1-score': 0.5116279069767442, 'support': 35}, 'accuracy': 0.685, 'macro avg': {'precision': 0.6660979526294661, 'recall': 0.7865800865800865, 'f1-score': 0.6395777911267485, 'support': 200}, 'weighted avg': {'precision': 0.8708701324769169, 'recall': 0.685, 'f1-score': 0.7227452158242512, 'support': 200}} \n","\n"]},{"output_type":"stream","name":"stderr","text":["loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--MoritzLaurer--mDeBERTa-v3-base-xnli-multilingual-nli-2mil7/snapshots/12dfea2a0b9ea8019b809105d4f62ffec7af622c/config.json\n","Model config DebertaV2Config {\n","  \"_name_or_path\": \"MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7\",\n","  \"architectures\": [\n","    \"DebertaV2ForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"entailment\",\n","    \"1\": \"neutral\",\n","    \"2\": \"contradiction\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"contradiction\": 2,\n","    \"entailment\": 0,\n","    \"neutral\": 1\n","  },\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"torch_dtype\": \"float16\",\n","  \"transformers_version\": \"4.23.0\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 251000\n","}\n","\n","loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--MoritzLaurer--mDeBERTa-v3-base-xnli-multilingual-nli-2mil7/snapshots/12dfea2a0b9ea8019b809105d4f62ffec7af622c/pytorch_model.bin\n","All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n","\n","All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n","The following columns in the training set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: hypothesis, label_nli_explicit, text_prepared. If hypothesis, label_nli_explicit, text_prepared are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 600\n","  Num Epochs = 12\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 900\n","/usr/local/lib/python3.10/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:745: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  attention_scores = torch.bmm(query_layer, key_layer.transpose(-1, -2)) / torch.tensor(\n","/usr/local/lib/python3.10/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:829: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  score += c2p_att / torch.tensor(scale, dtype=c2p_att.dtype)\n","/usr/local/lib/python3.10/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:852: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  score += p2c_att / torch.tensor(scale, dtype=p2c_att.dtype)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='900' max='900' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [900/900 06:05, Epoch 12/12]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.339100</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: hypothesis, label_nli_explicit, text_prepared. If hypothesis, label_nli_explicit, text_prepared are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 400\n","  Batch size = 32\n","\u001b[32m[I 2023-05-22 16:30:15,217]\u001b[0m Trial 1 finished with value: 2.8307616006041196 and parameters: {'learning_rate': 4e-05, 'num_train_epochs': 12, 'warmup_ratio': 0.3556211334079358}. Best is trial 1 with value: 2.8307616006041196.\u001b[0m\n","Trial: {'learning_rate': 2e-05, 'num_train_epochs': 6, 'warmup_ratio': 0.13851197621057668}\n"]},{"output_type":"stream","name":"stdout","text":["Highest probability prediction per premise:  [1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0]\n","Correct label per premise:  [0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n","Aggregate metrics:  {'f1_macro': 0.6481209079634276, 'f1_micro': 0.695, 'accuracy_balanced': 0.7926406926406926, 'accuracy_not_b': 0.695}\n","Detailed metrics:  {'Hostility towards Russia or Russians': {'precision': 0.9814814814814815, 'recall': 0.6424242424242425, 'f1-score': 0.7765567765567766, 'support': 165}, 'Other': {'precision': 0.358695652173913, 'recall': 0.9428571428571428, 'f1-score': 0.5196850393700787, 'support': 35}, 'accuracy': 0.695, 'macro avg': {'precision': 0.6700885668276972, 'recall': 0.7926406926406926, 'f1-score': 0.6481209079634276, 'support': 200}, 'weighted avg': {'precision': 0.8724939613526571, 'recall': 0.695, 'f1-score': 0.7316042225491046, 'support': 200}} \n","\n"]},{"output_type":"stream","name":"stderr","text":["loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--MoritzLaurer--mDeBERTa-v3-base-xnli-multilingual-nli-2mil7/snapshots/12dfea2a0b9ea8019b809105d4f62ffec7af622c/config.json\n","Model config DebertaV2Config {\n","  \"_name_or_path\": \"MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7\",\n","  \"architectures\": [\n","    \"DebertaV2ForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"entailment\",\n","    \"1\": \"neutral\",\n","    \"2\": \"contradiction\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"contradiction\": 2,\n","    \"entailment\": 0,\n","    \"neutral\": 1\n","  },\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"torch_dtype\": \"float16\",\n","  \"transformers_version\": \"4.23.0\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 251000\n","}\n","\n","loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--MoritzLaurer--mDeBERTa-v3-base-xnli-multilingual-nli-2mil7/snapshots/12dfea2a0b9ea8019b809105d4f62ffec7af622c/pytorch_model.bin\n","All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n","\n","All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n","The following columns in the training set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: hypothesis, label_nli_explicit, text_prepared. If hypothesis, label_nli_explicit, text_prepared are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 600\n","  Num Epochs = 6\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 450\n","/usr/local/lib/python3.10/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:745: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  attention_scores = torch.bmm(query_layer, key_layer.transpose(-1, -2)) / torch.tensor(\n","/usr/local/lib/python3.10/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:829: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  score += c2p_att / torch.tensor(scale, dtype=c2p_att.dtype)\n","/usr/local/lib/python3.10/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:852: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  score += p2c_att / torch.tensor(scale, dtype=p2c_att.dtype)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='450' max='450' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [450/450 03:03, Epoch 6/6]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: hypothesis, label_nli_explicit, text_prepared. If hypothesis, label_nli_explicit, text_prepared are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 400\n","  Batch size = 32\n","\u001b[32m[I 2023-05-22 16:33:30,250]\u001b[0m Trial 2 finished with value: 2.7819085638770678 and parameters: {'learning_rate': 2e-05, 'num_train_epochs': 6, 'warmup_ratio': 0.13851197621057668}. Best is trial 1 with value: 2.8307616006041196.\u001b[0m\n","Trial: {'learning_rate': 4e-05, 'num_train_epochs': 10, 'warmup_ratio': 0.16850792067367906}\n"]},{"output_type":"stream","name":"stdout","text":["Highest probability prediction per premise:  [1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0]\n","Correct label per premise:  [0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n","Aggregate metrics:  {'f1_macro': 0.6365838885523925, 'f1_micro': 0.685, 'accuracy_balanced': 0.7753246753246753, 'accuracy_not_b': 0.685}\n","Detailed metrics:  {'Hostility towards Russia or Russians': {'precision': 0.9722222222222222, 'recall': 0.6363636363636364, 'f1-score': 0.7692307692307692, 'support': 165}, 'Other': {'precision': 0.34782608695652173, 'recall': 0.9142857142857143, 'f1-score': 0.5039370078740156, 'support': 35}, 'accuracy': 0.685, 'macro avg': {'precision': 0.6600241545893719, 'recall': 0.7753246753246753, 'f1-score': 0.6365838885523925, 'support': 200}, 'weighted avg': {'precision': 0.8629528985507245, 'recall': 0.685, 'f1-score': 0.7228043609933372, 'support': 200}} \n","\n"]},{"output_type":"stream","name":"stderr","text":["loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--MoritzLaurer--mDeBERTa-v3-base-xnli-multilingual-nli-2mil7/snapshots/12dfea2a0b9ea8019b809105d4f62ffec7af622c/config.json\n","Model config DebertaV2Config {\n","  \"_name_or_path\": \"MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7\",\n","  \"architectures\": [\n","    \"DebertaV2ForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"entailment\",\n","    \"1\": \"neutral\",\n","    \"2\": \"contradiction\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"contradiction\": 2,\n","    \"entailment\": 0,\n","    \"neutral\": 1\n","  },\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"torch_dtype\": \"float16\",\n","  \"transformers_version\": \"4.23.0\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 251000\n","}\n","\n","loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--MoritzLaurer--mDeBERTa-v3-base-xnli-multilingual-nli-2mil7/snapshots/12dfea2a0b9ea8019b809105d4f62ffec7af622c/pytorch_model.bin\n","All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n","\n","All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n","The following columns in the training set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: hypothesis, label_nli_explicit, text_prepared. If hypothesis, label_nli_explicit, text_prepared are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 600\n","  Num Epochs = 10\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 750\n","/usr/local/lib/python3.10/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:745: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  attention_scores = torch.bmm(query_layer, key_layer.transpose(-1, -2)) / torch.tensor(\n","/usr/local/lib/python3.10/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:829: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  score += c2p_att / torch.tensor(scale, dtype=c2p_att.dtype)\n","/usr/local/lib/python3.10/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:852: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  score += p2c_att / torch.tensor(scale, dtype=p2c_att.dtype)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='750' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [750/750 05:05, Epoch 10/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.270300</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: hypothesis, label_nli_explicit, text_prepared. If hypothesis, label_nli_explicit, text_prepared are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 400\n","  Batch size = 32\n","\u001b[32m[I 2023-05-22 16:38:46,824]\u001b[0m Trial 3 finished with value: 2.900166501046135 and parameters: {'learning_rate': 4e-05, 'num_train_epochs': 10, 'warmup_ratio': 0.16850792067367906}. Best is trial 3 with value: 2.900166501046135.\u001b[0m\n","Trial: {'learning_rate': 9e-06, 'num_train_epochs': 8, 'warmup_ratio': 0.22640782282355432}\n"]},{"output_type":"stream","name":"stdout","text":["Highest probability prediction per premise:  [1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0]\n","Correct label per premise:  [0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n","Aggregate metrics:  {'f1_macro': 0.6654045962842299, 'f1_micro': 0.715, 'accuracy_balanced': 0.8047619047619048, 'accuracy_not_b': 0.715}\n","Detailed metrics:  {'Hostility towards Russia or Russians': {'precision': 0.9821428571428571, 'recall': 0.6666666666666666, 'f1-score': 0.7942238267148014, 'support': 165}, 'Other': {'precision': 0.375, 'recall': 0.9428571428571428, 'f1-score': 0.5365853658536585, 'support': 35}, 'accuracy': 0.715, 'macro avg': {'precision': 0.6785714285714286, 'recall': 0.8047619047619048, 'f1-score': 0.6654045962842299, 'support': 200}, 'weighted avg': {'precision': 0.875892857142857, 'recall': 0.715, 'f1-score': 0.7491370960641014, 'support': 200}} \n","\n"]},{"output_type":"stream","name":"stderr","text":["loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--MoritzLaurer--mDeBERTa-v3-base-xnli-multilingual-nli-2mil7/snapshots/12dfea2a0b9ea8019b809105d4f62ffec7af622c/config.json\n","Model config DebertaV2Config {\n","  \"_name_or_path\": \"MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7\",\n","  \"architectures\": [\n","    \"DebertaV2ForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"entailment\",\n","    \"1\": \"neutral\",\n","    \"2\": \"contradiction\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"contradiction\": 2,\n","    \"entailment\": 0,\n","    \"neutral\": 1\n","  },\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"torch_dtype\": \"float16\",\n","  \"transformers_version\": \"4.23.0\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 251000\n","}\n","\n","loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--MoritzLaurer--mDeBERTa-v3-base-xnli-multilingual-nli-2mil7/snapshots/12dfea2a0b9ea8019b809105d4f62ffec7af622c/pytorch_model.bin\n","All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n","\n","All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n","The following columns in the training set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: hypothesis, label_nli_explicit, text_prepared. If hypothesis, label_nli_explicit, text_prepared are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 600\n","  Num Epochs = 8\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 600\n","/usr/local/lib/python3.10/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:745: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  attention_scores = torch.bmm(query_layer, key_layer.transpose(-1, -2)) / torch.tensor(\n","/usr/local/lib/python3.10/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:829: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  score += c2p_att / torch.tensor(scale, dtype=c2p_att.dtype)\n","/usr/local/lib/python3.10/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:852: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  score += p2c_att / torch.tensor(scale, dtype=p2c_att.dtype)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [600/600 04:04, Epoch 8/8]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.353300</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: hypothesis, label_nli_explicit, text_prepared. If hypothesis, label_nli_explicit, text_prepared are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 400\n","  Batch size = 32\n","\u001b[32m[I 2023-05-22 16:43:02,755]\u001b[0m Trial 4 finished with value: 2.8337844483707038 and parameters: {'learning_rate': 9e-06, 'num_train_epochs': 8, 'warmup_ratio': 0.22640782282355432}. Best is trial 3 with value: 2.900166501046135.\u001b[0m\n","Trial: {'learning_rate': 9e-06, 'num_train_epochs': 12, 'warmup_ratio': 0.10867895322868468}\n"]},{"output_type":"stream","name":"stdout","text":["Highest probability prediction per premise:  [1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0]\n","Correct label per premise:  [0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n","Aggregate metrics:  {'f1_macro': 0.6493688639551193, 'f1_micro': 0.7, 'accuracy_balanced': 0.7844155844155845, 'accuracy_not_b': 0.7}\n","Detailed metrics:  {'Hostility towards Russia or Russians': {'precision': 0.972972972972973, 'recall': 0.6545454545454545, 'f1-score': 0.782608695652174, 'support': 165}, 'Other': {'precision': 0.3595505617977528, 'recall': 0.9142857142857143, 'f1-score': 0.5161290322580646, 'support': 35}, 'accuracy': 0.7, 'macro avg': {'precision': 0.6662617673853629, 'recall': 0.7844155844155845, 'f1-score': 0.6493688639551193, 'support': 200}, 'weighted avg': {'precision': 0.8656240510173094, 'recall': 0.7, 'f1-score': 0.7359747545582047, 'support': 200}} \n","\n"]},{"output_type":"stream","name":"stderr","text":["loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--MoritzLaurer--mDeBERTa-v3-base-xnli-multilingual-nli-2mil7/snapshots/12dfea2a0b9ea8019b809105d4f62ffec7af622c/config.json\n","Model config DebertaV2Config {\n","  \"_name_or_path\": \"MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7\",\n","  \"architectures\": [\n","    \"DebertaV2ForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"entailment\",\n","    \"1\": \"neutral\",\n","    \"2\": \"contradiction\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"contradiction\": 2,\n","    \"entailment\": 0,\n","    \"neutral\": 1\n","  },\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"torch_dtype\": \"float16\",\n","  \"transformers_version\": \"4.23.0\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 251000\n","}\n","\n","loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--MoritzLaurer--mDeBERTa-v3-base-xnli-multilingual-nli-2mil7/snapshots/12dfea2a0b9ea8019b809105d4f62ffec7af622c/pytorch_model.bin\n","All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n","\n","All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n","The following columns in the training set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: hypothesis, label_nli_explicit, text_prepared. If hypothesis, label_nli_explicit, text_prepared are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 600\n","  Num Epochs = 12\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 900\n","/usr/local/lib/python3.10/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:745: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  attention_scores = torch.bmm(query_layer, key_layer.transpose(-1, -2)) / torch.tensor(\n","/usr/local/lib/python3.10/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:829: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  score += c2p_att / torch.tensor(scale, dtype=c2p_att.dtype)\n","/usr/local/lib/python3.10/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:852: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  score += p2c_att / torch.tensor(scale, dtype=p2c_att.dtype)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='900' max='900' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [900/900 06:08, Epoch 12/12]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.337500</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: hypothesis, label_nli_explicit, text_prepared. If hypothesis, label_nli_explicit, text_prepared are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 400\n","  Batch size = 32\n","\u001b[32m[I 2023-05-22 16:49:22,443]\u001b[0m Trial 5 finished with value: 2.7991845461918454 and parameters: {'learning_rate': 9e-06, 'num_train_epochs': 12, 'warmup_ratio': 0.10867895322868468}. Best is trial 3 with value: 2.900166501046135.\u001b[0m\n","Trial: {'learning_rate': 9e-06, 'num_train_epochs': 16, 'warmup_ratio': 0.5641671230331442}\n"]},{"output_type":"stream","name":"stdout","text":["Highest probability prediction per premise:  [1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0]\n","Correct label per premise:  [0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n","Aggregate metrics:  {'f1_macro': 0.6408295678368672, 'f1_micro': 0.69, 'accuracy_balanced': 0.7783549783549784, 'accuracy_not_b': 0.69}\n","Detailed metrics:  {'Hostility towards Russia or Russians': {'precision': 0.9724770642201835, 'recall': 0.6424242424242425, 'f1-score': 0.7737226277372262, 'support': 165}, 'Other': {'precision': 0.3516483516483517, 'recall': 0.9142857142857143, 'f1-score': 0.507936507936508, 'support': 35}, 'accuracy': 0.69, 'macro avg': {'precision': 0.6620627079342676, 'recall': 0.7783549783549784, 'f1-score': 0.6408295678368672, 'support': 200}, 'weighted avg': {'precision': 0.863832039520113, 'recall': 0.69, 'f1-score': 0.7272100567721006, 'support': 200}} \n","\n"]},{"output_type":"stream","name":"stderr","text":["loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--MoritzLaurer--mDeBERTa-v3-base-xnli-multilingual-nli-2mil7/snapshots/12dfea2a0b9ea8019b809105d4f62ffec7af622c/config.json\n","Model config DebertaV2Config {\n","  \"_name_or_path\": \"MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7\",\n","  \"architectures\": [\n","    \"DebertaV2ForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"entailment\",\n","    \"1\": \"neutral\",\n","    \"2\": \"contradiction\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"contradiction\": 2,\n","    \"entailment\": 0,\n","    \"neutral\": 1\n","  },\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"torch_dtype\": \"float16\",\n","  \"transformers_version\": \"4.23.0\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 251000\n","}\n","\n","loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--MoritzLaurer--mDeBERTa-v3-base-xnli-multilingual-nli-2mil7/snapshots/12dfea2a0b9ea8019b809105d4f62ffec7af622c/pytorch_model.bin\n","All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n","\n","All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n","The following columns in the training set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: hypothesis, label_nli_explicit, text_prepared. If hypothesis, label_nli_explicit, text_prepared are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 600\n","  Num Epochs = 16\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 1200\n","/usr/local/lib/python3.10/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:745: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  attention_scores = torch.bmm(query_layer, key_layer.transpose(-1, -2)) / torch.tensor(\n","/usr/local/lib/python3.10/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:829: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  score += c2p_att / torch.tensor(scale, dtype=c2p_att.dtype)\n","/usr/local/lib/python3.10/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:852: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  score += p2c_att / torch.tensor(scale, dtype=p2c_att.dtype)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1200' max='1200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1200/1200 08:14, Epoch 16/16]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.527200</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.125800</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: hypothesis, label_nli_explicit, text_prepared. If hypothesis, label_nli_explicit, text_prepared are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 400\n","  Batch size = 32\n","\u001b[32m[I 2023-05-22 16:57:48,811]\u001b[0m Trial 6 finished with value: 2.761610033599874 and parameters: {'learning_rate': 9e-06, 'num_train_epochs': 16, 'warmup_ratio': 0.5641671230331442}. Best is trial 3 with value: 2.900166501046135.\u001b[0m\n","Trial: {'learning_rate': 9e-06, 'num_train_epochs': 12, 'warmup_ratio': 0.22004181237640907}\n"]},{"output_type":"stream","name":"stdout","text":["Highest probability prediction per premise:  [1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0]\n","Correct label per premise:  [0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n","Aggregate metrics:  {'f1_macro': 0.6310905530803939, 'f1_micro': 0.675, 'accuracy_balanced': 0.7805194805194805, 'accuracy_not_b': 0.675}\n","Detailed metrics:  {'Hostility towards Russia or Russians': {'precision': 0.9807692307692307, 'recall': 0.6181818181818182, 'f1-score': 0.758364312267658, 'support': 165}, 'Other': {'precision': 0.34375, 'recall': 0.9428571428571428, 'f1-score': 0.5038167938931298, 'support': 35}, 'accuracy': 0.675, 'macro avg': {'precision': 0.6622596153846154, 'recall': 0.7805194805194805, 'f1-score': 0.6310905530803939, 'support': 200}, 'weighted avg': {'precision': 0.8692908653846153, 'recall': 0.675, 'f1-score': 0.7138184965521155, 'support': 200}} \n","\n"]},{"output_type":"stream","name":"stderr","text":["loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--MoritzLaurer--mDeBERTa-v3-base-xnli-multilingual-nli-2mil7/snapshots/12dfea2a0b9ea8019b809105d4f62ffec7af622c/config.json\n","Model config DebertaV2Config {\n","  \"_name_or_path\": \"MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7\",\n","  \"architectures\": [\n","    \"DebertaV2ForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"entailment\",\n","    \"1\": \"neutral\",\n","    \"2\": \"contradiction\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"contradiction\": 2,\n","    \"entailment\": 0,\n","    \"neutral\": 1\n","  },\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"torch_dtype\": \"float16\",\n","  \"transformers_version\": \"4.23.0\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 251000\n","}\n","\n","loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--MoritzLaurer--mDeBERTa-v3-base-xnli-multilingual-nli-2mil7/snapshots/12dfea2a0b9ea8019b809105d4f62ffec7af622c/pytorch_model.bin\n","All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n","\n","All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n","The following columns in the training set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: hypothesis, label_nli_explicit, text_prepared. If hypothesis, label_nli_explicit, text_prepared are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 600\n","  Num Epochs = 12\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 900\n","/usr/local/lib/python3.10/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:745: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  attention_scores = torch.bmm(query_layer, key_layer.transpose(-1, -2)) / torch.tensor(\n","/usr/local/lib/python3.10/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:829: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  score += c2p_att / torch.tensor(scale, dtype=c2p_att.dtype)\n","/usr/local/lib/python3.10/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:852: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  score += p2c_att / torch.tensor(scale, dtype=p2c_att.dtype)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='900' max='900' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [900/900 06:06, Epoch 12/12]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.380500</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: hypothesis, label_nli_explicit, text_prepared. If hypothesis, label_nli_explicit, text_prepared are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 400\n","  Batch size = 32\n","\u001b[32m[I 2023-05-22 17:04:06,786]\u001b[0m Trial 7 finished with value: 2.8684547256808135 and parameters: {'learning_rate': 9e-06, 'num_train_epochs': 12, 'warmup_ratio': 0.22004181237640907}. Best is trial 3 with value: 2.900166501046135.\u001b[0m\n","Trial: {'learning_rate': 4e-05, 'num_train_epochs': 4, 'warmup_ratio': 0.17409647669459866}\n"]},{"output_type":"stream","name":"stdout","text":["Highest probability prediction per premise:  [1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0]\n","Correct label per premise:  [0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n","Aggregate metrics:  {'f1_macro': 0.6579785352046231, 'f1_micro': 0.7100000000000001, 'accuracy_balanced': 0.7904761904761904, 'accuracy_not_b': 0.71}\n","Detailed metrics:  {'Hostility towards Russia or Russians': {'precision': 0.9734513274336283, 'recall': 0.6666666666666666, 'f1-score': 0.79136690647482, 'support': 165}, 'Other': {'precision': 0.367816091954023, 'recall': 0.9142857142857143, 'f1-score': 0.5245901639344263, 'support': 35}, 'accuracy': 0.71, 'macro avg': {'precision': 0.6706337096938256, 'recall': 0.7904761904761904, 'f1-score': 0.6579785352046231, 'support': 200}, 'weighted avg': {'precision': 0.8674651612246974, 'recall': 0.71, 'f1-score': 0.7446809765302511, 'support': 200}} \n","\n"]},{"output_type":"stream","name":"stderr","text":["loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--MoritzLaurer--mDeBERTa-v3-base-xnli-multilingual-nli-2mil7/snapshots/12dfea2a0b9ea8019b809105d4f62ffec7af622c/config.json\n","Model config DebertaV2Config {\n","  \"_name_or_path\": \"MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7\",\n","  \"architectures\": [\n","    \"DebertaV2ForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"entailment\",\n","    \"1\": \"neutral\",\n","    \"2\": \"contradiction\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"contradiction\": 2,\n","    \"entailment\": 0,\n","    \"neutral\": 1\n","  },\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"torch_dtype\": \"float16\",\n","  \"transformers_version\": \"4.23.0\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 251000\n","}\n","\n","loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--MoritzLaurer--mDeBERTa-v3-base-xnli-multilingual-nli-2mil7/snapshots/12dfea2a0b9ea8019b809105d4f62ffec7af622c/pytorch_model.bin\n","All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n","\n","All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n","The following columns in the training set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: hypothesis, label_nli_explicit, text_prepared. If hypothesis, label_nli_explicit, text_prepared are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 600\n","  Num Epochs = 4\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 300\n","/usr/local/lib/python3.10/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:745: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  attention_scores = torch.bmm(query_layer, key_layer.transpose(-1, -2)) / torch.tensor(\n","/usr/local/lib/python3.10/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:829: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  score += c2p_att / torch.tensor(scale, dtype=c2p_att.dtype)\n","/usr/local/lib/python3.10/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:852: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  score += p2c_att / torch.tensor(scale, dtype=p2c_att.dtype)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [300/300 02:01, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: hypothesis, label_nli_explicit, text_prepared. If hypothesis, label_nli_explicit, text_prepared are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 400\n","  Batch size = 32\n","\u001b[32m[I 2023-05-22 17:06:19,606]\u001b[0m Trial 8 finished with value: 2.764647313470843 and parameters: {'learning_rate': 4e-05, 'num_train_epochs': 4, 'warmup_ratio': 0.17409647669459866}. Best is trial 3 with value: 2.900166501046135.\u001b[0m\n","Trial: {'learning_rate': 4e-05, 'num_train_epochs': 16, 'warmup_ratio': 0.3444424132703427}\n"]},{"output_type":"stream","name":"stdout","text":["Highest probability prediction per premise:  [1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0]\n","Correct label per premise:  [0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n","Aggregate metrics:  {'f1_macro': 0.6323529411764706, 'f1_micro': 0.68, 'accuracy_balanced': 0.7722943722943723, 'accuracy_not_b': 0.68}\n","Detailed metrics:  {'Hostility towards Russia or Russians': {'precision': 0.9719626168224299, 'recall': 0.6303030303030303, 'f1-score': 0.7647058823529411, 'support': 165}, 'Other': {'precision': 0.34408602150537637, 'recall': 0.9142857142857143, 'f1-score': 0.5, 'support': 35}, 'accuracy': 0.68, 'macro avg': {'precision': 0.6580243191639031, 'recall': 0.7722943722943723, 'f1-score': 0.6323529411764706, 'support': 200}, 'weighted avg': {'precision': 0.8620842126419455, 'recall': 0.68, 'f1-score': 0.7183823529411765, 'support': 200}} \n","\n"]},{"output_type":"stream","name":"stderr","text":["loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--MoritzLaurer--mDeBERTa-v3-base-xnli-multilingual-nli-2mil7/snapshots/12dfea2a0b9ea8019b809105d4f62ffec7af622c/config.json\n","Model config DebertaV2Config {\n","  \"_name_or_path\": \"MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7\",\n","  \"architectures\": [\n","    \"DebertaV2ForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"entailment\",\n","    \"1\": \"neutral\",\n","    \"2\": \"contradiction\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"contradiction\": 2,\n","    \"entailment\": 0,\n","    \"neutral\": 1\n","  },\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"torch_dtype\": \"float16\",\n","  \"transformers_version\": \"4.23.0\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 251000\n","}\n","\n","loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--MoritzLaurer--mDeBERTa-v3-base-xnli-multilingual-nli-2mil7/snapshots/12dfea2a0b9ea8019b809105d4f62ffec7af622c/pytorch_model.bin\n","All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n","\n","All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n","The following columns in the training set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: hypothesis, label_nli_explicit, text_prepared. If hypothesis, label_nli_explicit, text_prepared are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 600\n","  Num Epochs = 16\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 1200\n","/usr/local/lib/python3.10/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:745: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  attention_scores = torch.bmm(query_layer, key_layer.transpose(-1, -2)) / torch.tensor(\n","/usr/local/lib/python3.10/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:829: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  score += c2p_att / torch.tensor(scale, dtype=c2p_att.dtype)\n","/usr/local/lib/python3.10/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:852: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  score += p2c_att / torch.tensor(scale, dtype=p2c_att.dtype)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1200' max='1200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1200/1200 08:08, Epoch 16/16]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.370700</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.025700</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: hypothesis, label_nli_explicit, text_prepared. If hypothesis, label_nli_explicit, text_prepared are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 400\n","  Batch size = 32\n","\u001b[32m[I 2023-05-22 17:14:39,981]\u001b[0m Trial 9 finished with value: 2.62995074509563 and parameters: {'learning_rate': 4e-05, 'num_train_epochs': 16, 'warmup_ratio': 0.3444424132703427}. Best is trial 3 with value: 2.900166501046135.\u001b[0m\n","Trial: {'learning_rate': 4e-05, 'num_train_epochs': 8, 'warmup_ratio': 0.3074753412129321}\n"]},{"output_type":"stream","name":"stdout","text":["Highest probability prediction per premise:  [1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0]\n","Correct label per premise:  [0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n","Aggregate metrics:  {'f1_macro': 0.60012390526879, 'f1_micro': 0.645, 'accuracy_balanced': 0.7398268398268398, 'accuracy_not_b': 0.645}\n","Detailed metrics:  {'Hostility towards Russia or Russians': {'precision': 0.9607843137254902, 'recall': 0.593939393939394, 'f1-score': 0.7340823970037454, 'support': 165}, 'Other': {'precision': 0.3163265306122449, 'recall': 0.8857142857142857, 'f1-score': 0.4661654135338346, 'support': 35}, 'accuracy': 0.645, 'macro avg': {'precision': 0.6385554221688676, 'recall': 0.7398268398268398, 'f1-score': 0.60012390526879, 'support': 200}, 'weighted avg': {'precision': 0.8480042016806724, 'recall': 0.645, 'f1-score': 0.6871969248965111, 'support': 200}} \n","\n"]},{"output_type":"stream","name":"stderr","text":["loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--MoritzLaurer--mDeBERTa-v3-base-xnli-multilingual-nli-2mil7/snapshots/12dfea2a0b9ea8019b809105d4f62ffec7af622c/config.json\n","Model config DebertaV2Config {\n","  \"_name_or_path\": \"MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7\",\n","  \"architectures\": [\n","    \"DebertaV2ForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"entailment\",\n","    \"1\": \"neutral\",\n","    \"2\": \"contradiction\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"contradiction\": 2,\n","    \"entailment\": 0,\n","    \"neutral\": 1\n","  },\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"torch_dtype\": \"float16\",\n","  \"transformers_version\": \"4.23.0\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 251000\n","}\n","\n","loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--MoritzLaurer--mDeBERTa-v3-base-xnli-multilingual-nli-2mil7/snapshots/12dfea2a0b9ea8019b809105d4f62ffec7af622c/pytorch_model.bin\n","All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n","\n","All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n","The following columns in the training set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: hypothesis, label_nli_explicit, text_prepared. If hypothesis, label_nli_explicit, text_prepared are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 600\n","  Num Epochs = 8\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 600\n","/usr/local/lib/python3.10/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:745: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  attention_scores = torch.bmm(query_layer, key_layer.transpose(-1, -2)) / torch.tensor(\n","/usr/local/lib/python3.10/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:829: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  score += c2p_att / torch.tensor(scale, dtype=c2p_att.dtype)\n","/usr/local/lib/python3.10/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:852: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  score += p2c_att / torch.tensor(scale, dtype=p2c_att.dtype)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [600/600 04:04, Epoch 8/8]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.281000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: hypothesis, label_nli_explicit, text_prepared. If hypothesis, label_nli_explicit, text_prepared are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 400\n","  Batch size = 32\n","\u001b[32m[I 2023-05-22 17:18:56,168]\u001b[0m Trial 10 finished with value: 2.858944188042346 and parameters: {'learning_rate': 4e-05, 'num_train_epochs': 8, 'warmup_ratio': 0.3074753412129321}. Best is trial 3 with value: 2.900166501046135.\u001b[0m\n","Trial: {'learning_rate': 9e-06, 'num_train_epochs': 10, 'warmup_ratio': 0.20743531605815804}\n"]},{"output_type":"stream","name":"stdout","text":["Highest probability prediction per premise:  [1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0]\n","Correct label per premise:  [0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n","Aggregate metrics:  {'f1_macro': 0.6537926728908312, 'f1_micro': 0.695, 'accuracy_balanced': 0.8151515151515152, 'accuracy_not_b': 0.695}\n","Detailed metrics:  {'Hostility towards Russia or Russians': {'precision': 1.0, 'recall': 0.6303030303030303, 'f1-score': 0.7732342007434944, 'support': 165}, 'Other': {'precision': 0.3645833333333333, 'recall': 1.0, 'f1-score': 0.5343511450381679, 'support': 35}, 'accuracy': 0.695, 'macro avg': {'precision': 0.6822916666666666, 'recall': 0.8151515151515152, 'f1-score': 0.6537926728908312, 'support': 200}, 'weighted avg': {'precision': 0.8888020833333333, 'recall': 0.695, 'f1-score': 0.7314296659950622, 'support': 200}} \n","\n"]},{"output_type":"stream","name":"stderr","text":["loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--MoritzLaurer--mDeBERTa-v3-base-xnli-multilingual-nli-2mil7/snapshots/12dfea2a0b9ea8019b809105d4f62ffec7af622c/config.json\n","Model config DebertaV2Config {\n","  \"_name_or_path\": \"MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7\",\n","  \"architectures\": [\n","    \"DebertaV2ForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"entailment\",\n","    \"1\": \"neutral\",\n","    \"2\": \"contradiction\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"contradiction\": 2,\n","    \"entailment\": 0,\n","    \"neutral\": 1\n","  },\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"torch_dtype\": \"float16\",\n","  \"transformers_version\": \"4.23.0\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 251000\n","}\n","\n","loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--MoritzLaurer--mDeBERTa-v3-base-xnli-multilingual-nli-2mil7/snapshots/12dfea2a0b9ea8019b809105d4f62ffec7af622c/pytorch_model.bin\n","All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n","\n","All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n","The following columns in the training set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: hypothesis, label_nli_explicit, text_prepared. If hypothesis, label_nli_explicit, text_prepared are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 600\n","  Num Epochs = 10\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 750\n","/usr/local/lib/python3.10/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:745: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  attention_scores = torch.bmm(query_layer, key_layer.transpose(-1, -2)) / torch.tensor(\n","/usr/local/lib/python3.10/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:829: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  score += c2p_att / torch.tensor(scale, dtype=c2p_att.dtype)\n","/usr/local/lib/python3.10/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:852: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  score += p2c_att / torch.tensor(scale, dtype=p2c_att.dtype)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='750' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [750/750 05:05, Epoch 10/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.359400</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: hypothesis, label_nli_explicit, text_prepared. If hypothesis, label_nli_explicit, text_prepared are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 400\n","  Batch size = 32\n","\u001b[32m[I 2023-05-22 17:24:13,085]\u001b[0m Trial 11 finished with value: 2.8654285714285717 and parameters: {'learning_rate': 9e-06, 'num_train_epochs': 10, 'warmup_ratio': 0.20743531605815804}. Best is trial 3 with value: 2.900166501046135.\u001b[0m\n","Trial: {'learning_rate': 9e-06, 'num_train_epochs': 14, 'warmup_ratio': 0.16525941196773627}\n"]},{"output_type":"stream","name":"stdout","text":["Highest probability prediction per premise:  [1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0]\n","Correct label per premise:  [0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n","Aggregate metrics:  {'f1_macro': 0.6567272727272727, 'f1_micro': 0.705, 'accuracy_balanced': 0.7987012987012987, 'accuracy_not_b': 0.705}\n","Detailed metrics:  {'Hostility towards Russia or Russians': {'precision': 0.9818181818181818, 'recall': 0.6545454545454545, 'f1-score': 0.7854545454545455, 'support': 165}, 'Other': {'precision': 0.36666666666666664, 'recall': 0.9428571428571428, 'f1-score': 0.5279999999999999, 'support': 35}, 'accuracy': 0.705, 'macro avg': {'precision': 0.6742424242424242, 'recall': 0.7987012987012987, 'f1-score': 0.6567272727272727, 'support': 200}, 'weighted avg': {'precision': 0.8741666666666668, 'recall': 0.705, 'f1-score': 0.7404000000000001, 'support': 200}} \n","\n"]},{"output_type":"stream","name":"stderr","text":["loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--MoritzLaurer--mDeBERTa-v3-base-xnli-multilingual-nli-2mil7/snapshots/12dfea2a0b9ea8019b809105d4f62ffec7af622c/config.json\n","Model config DebertaV2Config {\n","  \"_name_or_path\": \"MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7\",\n","  \"architectures\": [\n","    \"DebertaV2ForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"entailment\",\n","    \"1\": \"neutral\",\n","    \"2\": \"contradiction\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"contradiction\": 2,\n","    \"entailment\": 0,\n","    \"neutral\": 1\n","  },\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"torch_dtype\": \"float16\",\n","  \"transformers_version\": \"4.23.0\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 251000\n","}\n","\n","loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--MoritzLaurer--mDeBERTa-v3-base-xnli-multilingual-nli-2mil7/snapshots/12dfea2a0b9ea8019b809105d4f62ffec7af622c/pytorch_model.bin\n","All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n","\n","All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n","The following columns in the training set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: hypothesis, label_nli_explicit, text_prepared. If hypothesis, label_nli_explicit, text_prepared are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 600\n","  Num Epochs = 14\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 1050\n","/usr/local/lib/python3.10/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:745: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  attention_scores = torch.bmm(query_layer, key_layer.transpose(-1, -2)) / torch.tensor(\n","/usr/local/lib/python3.10/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:829: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  score += c2p_att / torch.tensor(scale, dtype=c2p_att.dtype)\n","/usr/local/lib/python3.10/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:852: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  score += p2c_att / torch.tensor(scale, dtype=p2c_att.dtype)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1050' max='1050' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1050/1050 07:07, Epoch 14/14]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.370600</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.044400</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: hypothesis, label_nli_explicit, text_prepared. If hypothesis, label_nli_explicit, text_prepared are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 400\n","  Batch size = 32\n","\u001b[32m[I 2023-05-22 17:31:32,417]\u001b[0m Trial 12 finished with value: 2.7991845461918454 and parameters: {'learning_rate': 9e-06, 'num_train_epochs': 14, 'warmup_ratio': 0.16525941196773627}. Best is trial 3 with value: 2.900166501046135.\u001b[0m\n","Trial: {'learning_rate': 4e-05, 'num_train_epochs': 10, 'warmup_ratio': 0.2674310847355726}\n"]},{"output_type":"stream","name":"stdout","text":["Highest probability prediction per premise:  [1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0]\n","Correct label per premise:  [0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n","Aggregate metrics:  {'f1_macro': 0.6408295678368672, 'f1_micro': 0.69, 'accuracy_balanced': 0.7783549783549784, 'accuracy_not_b': 0.69}\n","Detailed metrics:  {'Hostility towards Russia or Russians': {'precision': 0.9724770642201835, 'recall': 0.6424242424242425, 'f1-score': 0.7737226277372262, 'support': 165}, 'Other': {'precision': 0.3516483516483517, 'recall': 0.9142857142857143, 'f1-score': 0.507936507936508, 'support': 35}, 'accuracy': 0.69, 'macro avg': {'precision': 0.6620627079342676, 'recall': 0.7783549783549784, 'f1-score': 0.6408295678368672, 'support': 200}, 'weighted avg': {'precision': 0.863832039520113, 'recall': 0.69, 'f1-score': 0.7272100567721006, 'support': 200}} \n","\n"]},{"output_type":"stream","name":"stderr","text":["loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--MoritzLaurer--mDeBERTa-v3-base-xnli-multilingual-nli-2mil7/snapshots/12dfea2a0b9ea8019b809105d4f62ffec7af622c/config.json\n","Model config DebertaV2Config {\n","  \"_name_or_path\": \"MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7\",\n","  \"architectures\": [\n","    \"DebertaV2ForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"entailment\",\n","    \"1\": \"neutral\",\n","    \"2\": \"contradiction\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"contradiction\": 2,\n","    \"entailment\": 0,\n","    \"neutral\": 1\n","  },\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"torch_dtype\": \"float16\",\n","  \"transformers_version\": \"4.23.0\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 251000\n","}\n","\n","loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--MoritzLaurer--mDeBERTa-v3-base-xnli-multilingual-nli-2mil7/snapshots/12dfea2a0b9ea8019b809105d4f62ffec7af622c/pytorch_model.bin\n","All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n","\n","All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n","The following columns in the training set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: hypothesis, label_nli_explicit, text_prepared. If hypothesis, label_nli_explicit, text_prepared are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 600\n","  Num Epochs = 10\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 750\n","/usr/local/lib/python3.10/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:745: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  attention_scores = torch.bmm(query_layer, key_layer.transpose(-1, -2)) / torch.tensor(\n","/usr/local/lib/python3.10/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:829: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  score += c2p_att / torch.tensor(scale, dtype=c2p_att.dtype)\n","/usr/local/lib/python3.10/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:852: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  score += p2c_att / torch.tensor(scale, dtype=p2c_att.dtype)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='750' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [750/750 05:05, Epoch 10/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.287200</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: hypothesis, label_nli_explicit, text_prepared. If hypothesis, label_nli_explicit, text_prepared are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 400\n","  Batch size = 32\n","\u001b[32m[I 2023-05-22 17:36:49,253]\u001b[0m Trial 13 finished with value: 2.796157877706835 and parameters: {'learning_rate': 4e-05, 'num_train_epochs': 10, 'warmup_ratio': 0.2674310847355726}. Best is trial 3 with value: 2.900166501046135.\u001b[0m\n","Trial: {'learning_rate': 2e-05, 'num_train_epochs': 8, 'warmup_ratio': 0.18800767011432823}\n"]},{"output_type":"stream","name":"stdout","text":["Highest probability prediction per premise:  [1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0]\n","Correct label per premise:  [0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n","Aggregate metrics:  {'f1_macro': 0.6395777911267485, 'f1_micro': 0.685, 'accuracy_balanced': 0.7865800865800865, 'accuracy_not_b': 0.685}\n","Detailed metrics:  {'Hostility towards Russia or Russians': {'precision': 0.9811320754716981, 'recall': 0.6303030303030303, 'f1-score': 0.7675276752767528, 'support': 165}, 'Other': {'precision': 0.35106382978723405, 'recall': 0.9428571428571428, 'f1-score': 0.5116279069767442, 'support': 35}, 'accuracy': 0.685, 'macro avg': {'precision': 0.6660979526294661, 'recall': 0.7865800865800865, 'f1-score': 0.6395777911267485, 'support': 200}, 'weighted avg': {'precision': 0.8708701324769169, 'recall': 0.685, 'f1-score': 0.7227452158242512, 'support': 200}} \n","\n"]},{"output_type":"stream","name":"stderr","text":["loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--MoritzLaurer--mDeBERTa-v3-base-xnli-multilingual-nli-2mil7/snapshots/12dfea2a0b9ea8019b809105d4f62ffec7af622c/config.json\n","Model config DebertaV2Config {\n","  \"_name_or_path\": \"MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7\",\n","  \"architectures\": [\n","    \"DebertaV2ForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"entailment\",\n","    \"1\": \"neutral\",\n","    \"2\": \"contradiction\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"contradiction\": 2,\n","    \"entailment\": 0,\n","    \"neutral\": 1\n","  },\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"torch_dtype\": \"float16\",\n","  \"transformers_version\": \"4.23.0\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 251000\n","}\n","\n","loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--MoritzLaurer--mDeBERTa-v3-base-xnli-multilingual-nli-2mil7/snapshots/12dfea2a0b9ea8019b809105d4f62ffec7af622c/pytorch_model.bin\n","All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n","\n","All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n","The following columns in the training set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: hypothesis, label_nli_explicit, text_prepared. If hypothesis, label_nli_explicit, text_prepared are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 600\n","  Num Epochs = 8\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 600\n","/usr/local/lib/python3.10/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:745: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  attention_scores = torch.bmm(query_layer, key_layer.transpose(-1, -2)) / torch.tensor(\n","/usr/local/lib/python3.10/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:829: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  score += c2p_att / torch.tensor(scale, dtype=c2p_att.dtype)\n","/usr/local/lib/python3.10/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:852: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  score += p2c_att / torch.tensor(scale, dtype=p2c_att.dtype)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [600/600 04:04, Epoch 8/8]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.266200</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: hypothesis, label_nli_explicit, text_prepared. If hypothesis, label_nli_explicit, text_prepared are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 400\n","  Batch size = 32\n","\u001b[32m[I 2023-05-22 17:41:04,678]\u001b[0m Trial 14 finished with value: 2.928467674058225 and parameters: {'learning_rate': 2e-05, 'num_train_epochs': 8, 'warmup_ratio': 0.18800767011432823}. Best is trial 14 with value: 2.928467674058225.\u001b[0m\n","Trial: {'learning_rate': 2e-05, 'num_train_epochs': 8, 'warmup_ratio': 0.16352751048458855}\n"]},{"output_type":"stream","name":"stdout","text":["Highest probability prediction per premise:  [1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0]\n","Correct label per premise:  [0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n","Aggregate metrics:  {'f1_macro': 0.671194946785498, 'f1_micro': 0.715, 'accuracy_balanced': 0.8272727272727273, 'accuracy_not_b': 0.715}\n","Detailed metrics:  {'Hostility towards Russia or Russians': {'precision': 1.0, 'recall': 0.6545454545454545, 'f1-score': 0.7912087912087912, 'support': 165}, 'Other': {'precision': 0.3804347826086957, 'recall': 1.0, 'f1-score': 0.5511811023622047, 'support': 35}, 'accuracy': 0.715, 'macro avg': {'precision': 0.6902173913043479, 'recall': 0.8272727272727273, 'f1-score': 0.671194946785498, 'support': 200}, 'weighted avg': {'precision': 0.8915760869565217, 'recall': 0.715, 'f1-score': 0.7492039456606385, 'support': 200}} \n","\n"]},{"output_type":"stream","name":"stderr","text":["loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--MoritzLaurer--mDeBERTa-v3-base-xnli-multilingual-nli-2mil7/snapshots/12dfea2a0b9ea8019b809105d4f62ffec7af622c/config.json\n","Model config DebertaV2Config {\n","  \"_name_or_path\": \"MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7\",\n","  \"architectures\": [\n","    \"DebertaV2ForSequenceClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"entailment\",\n","    \"1\": \"neutral\",\n","    \"2\": \"contradiction\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"contradiction\": 2,\n","    \"entailment\": 0,\n","    \"neutral\": 1\n","  },\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"torch_dtype\": \"float16\",\n","  \"transformers_version\": \"4.23.0\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 251000\n","}\n","\n","loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--MoritzLaurer--mDeBERTa-v3-base-xnli-multilingual-nli-2mil7/snapshots/12dfea2a0b9ea8019b809105d4f62ffec7af622c/pytorch_model.bin\n","All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n","\n","All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n","The following columns in the training set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: hypothesis, label_nli_explicit, text_prepared. If hypothesis, label_nli_explicit, text_prepared are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 600\n","  Num Epochs = 8\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 600\n","/usr/local/lib/python3.10/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:745: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  attention_scores = torch.bmm(query_layer, key_layer.transpose(-1, -2)) / torch.tensor(\n","/usr/local/lib/python3.10/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:829: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  score += c2p_att / torch.tensor(scale, dtype=c2p_att.dtype)\n","/usr/local/lib/python3.10/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:852: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  score += p2c_att / torch.tensor(scale, dtype=p2c_att.dtype)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [600/600 04:04, Epoch 8/8]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.273800</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: hypothesis, label_nli_explicit, text_prepared. If hypothesis, label_nli_explicit, text_prepared are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 400\n","  Batch size = 32\n","\u001b[32m[I 2023-05-22 17:45:20,769]\u001b[0m Trial 15 finished with value: 2.9458910270589103 and parameters: {'learning_rate': 2e-05, 'num_train_epochs': 8, 'warmup_ratio': 0.16352751048458855}. Best is trial 15 with value: 2.9458910270589103.\u001b[0m\n"]},{"output_type":"stream","name":"stdout","text":["Highest probability prediction per premise:  [1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0]\n","Correct label per premise:  [0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n","Aggregate metrics:  {'f1_macro': 0.67558799675588, 'f1_micro': 0.72, 'accuracy_balanced': 0.8303030303030303, 'accuracy_not_b': 0.72}\n","Detailed metrics:  {'Hostility towards Russia or Russians': {'precision': 1.0, 'recall': 0.6606060606060606, 'f1-score': 0.7956204379562044, 'support': 165}, 'Other': {'precision': 0.38461538461538464, 'recall': 1.0, 'f1-score': 0.5555555555555556, 'support': 35}, 'accuracy': 0.72, 'macro avg': {'precision': 0.6923076923076923, 'recall': 0.8303030303030303, 'f1-score': 0.67558799675588, 'support': 200}, 'weighted avg': {'precision': 0.8923076923076922, 'recall': 0.72, 'f1-score': 0.7536090835360909, 'support': 200}} \n","\n"]}]},{"cell_type":"code","source":["# show best hyperparameters based on hp-search\n","print(best_run)"],"metadata":{"id":"AjG3MjZQK-8J","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684777520206,"user_tz":-60,"elapsed":24,"user":{"displayName":"Yara Kyrychenko","userId":"07690358214170724243"}},"outputId":"743045da-346a-4551-cb68-b82d3e30baed"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["BestRun(run_id='15', objective=2.9458910270589103, hyperparameters={'learning_rate': 2e-05, 'num_train_epochs': 8, 'warmup_ratio': 0.16352751048458855})\n"]}]},{"cell_type":"markdown","source":["**Training Time with optimised hyperparameters!**\n","\n","Here we can use the original train and test set again."],"metadata":{"id":"J8SWpFU7ep0k"}},{"cell_type":"code","source":["# update the training arguments with the best hyperparameters\n","for k,v in best_run.hyperparameters.items():\n","    setattr(train_args, k, v)\n","print(\"\\n\", train_args)\n","\n","# hp-search with hf causes errors with FP16 for some reason\n","#setattr(train_args, \"fp16\", False)\n","#setattr(train_args, \"fp16_full_eval\", False)"],"metadata":{"id":"E5cmYQpse1HN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684777520206,"user_tz":-60,"elapsed":11,"user":{"displayName":"Yara Kyrychenko","userId":"07690358214170724243"}},"outputId":"20cdaa2c-d319-434f-8ea2-bd6934b2264c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," TrainingArguments(\n","_n_gpu=1,\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","auto_find_batch_size=False,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=None,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_pin_memory=True,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","ddp_timeout=1800,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","do_eval=False,\n","do_predict=False,\n","do_train=False,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_steps=None,\n","evaluation_strategy=no,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","fsdp=[],\n","fsdp_min_num_params=0,\n","fsdp_transformer_layer_cls_to_wrap=None,\n","full_determinism=False,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","greater_is_better=True,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_model_id=None,\n","hub_private_repo=False,\n","hub_strategy=every_save,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","include_inputs_for_metrics=False,\n","jit_mode_eval=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=2e-05,\n","length_column_name=length,\n","load_best_model_at_end=True,\n","local_rank=-1,\n","log_level=passive,\n","log_level_replica=passive,\n","log_on_each_node=True,\n","logging_dir=./logs/BERT-nli-ua-sol,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=500,\n","logging_strategy=steps,\n","lr_scheduler_type=linear,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=accuracy,\n","mp_parameters=,\n","no_cuda=False,\n","num_train_epochs=8,\n","optim=adamw_hf,\n","output_dir=./results/BERT-nli-ua-sol,\n","overwrite_output_dir=False,\n","past_index=-1,\n","per_device_eval_batch_size=32,\n","per_device_train_batch_size=8,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","ray_scope=last,\n","remove_unused_columns=True,\n","report_to=['tensorboard'],\n","resume_from_checkpoint=None,\n","run_name=./results/BERT-nli-ua-sol,\n","save_on_each_node=False,\n","save_steps=500,\n","save_strategy=no,\n","save_total_limit=None,\n","seed=42,\n","sharded_ddp=[],\n","skip_memory_metrics=True,\n","tf32=None,\n","torchdynamo=None,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_ipex=False,\n","use_legacy_prediction_loop=False,\n","use_mps_device=False,\n","warmup_ratio=0.16352751048458855,\n","warmup_steps=0,\n","weight_decay=0.1,\n","xpu_backend=None,\n",")\n"]}]},{"cell_type":"code","source":["dataset = datasets.DatasetDict({\n","    \"train\": datasets.Dataset.from_pandas(df_train_formatted),\n","    \"test\": datasets.Dataset.from_pandas(df_test_formatted)\n","})\n","\n","# tokenize\n","def tokenize_nli_format(examples):\n","  return tokenizer(examples[\"text_prepared\"], examples[\"hypothesis\"], truncation=True, max_length=512)  #512 max_length can be reduced to e.g. 256 to increase speed, but long texts will be cut off\n","dataset[\"train\"] = dataset[\"train\"].map(tokenize_nli_format, batched=True)\n","dataset[\"test\"] = dataset[\"test\"].map(tokenize_nli_format, batched=True)\n","\n","# remove unnecessary columns for model training\n","\n","dataset = dataset.remove_columns(['label_text','Unnamed: 0', 'X', 'date', 'text', 'user_id','Zperiod', 'lang', 'source','descUAid', 'descRUid', 'solUAid', 'hostRUid', 'hostUAid',\n","       'solRUid', 'Unnamed: 14', '__index_level_0__'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["dfba2da0c2d948c6867083a6355eefca","e7139293e45342e082e90a22b457e1e4","a07173df610e40cca5ad7bf9ad658272","d1e0069fb7db491ea20620373b75cb0d","cf556d87499140cba08524d3b9102c3f","70e55260058f454d916077b858f7f997","164bf5707e664884b2370a7ad7e581cd","a53aae2f6a3543d9a710b3a05bcd630b","abc1666d68884147a00bf4792e1be604","6428a7f1d1e24d9bbe7165b998ec35e9","8eedaae0bd954a44a69c98786aada1ca","af9563d8679d4995b7f76366c40953dd","8e416623d1d0460ab46d0eb89b3a3fe9","df9eb808b63b4bb186500b9606a9f123","b8713d3dbc224f7c82e9d3330c5889ac","66eb1079c71e4c2cac0cbf7719c476aa","a8a4789437884773bacda06caee6c01e","e5a254b5ee96492ba17a5c7628128bf0","12fe2a1f7c844fb1b58bc8cc6324d202","2456cd23f24c4bff999041b17756336c","3acf90dd75584f3483faf61c259f398b","f9c66f76dbc54197893237654bc13000"]},"id":"G8vfECHn5EFh","executionInfo":{"status":"ok","timestamp":1684777520506,"user_tz":-60,"elapsed":308,"user":{"displayName":"Yara Kyrychenko","userId":"07690358214170724243"}},"outputId":"c2ea961b-6881-4d29-be87-5fad007d2ad4"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/3 [00:00<?, ?ba/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dfba2da0c2d948c6867083a6355eefca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af9563d8679d4995b7f76366c40953dd"}},"metadata":{}}]},{"cell_type":"code","source":["# Training\n","trainer = Trainer(\n","    model=model,\n","    tokenizer=tokenizer,\n","    args=train_args,\n","    train_dataset=dataset[\"train\"],  #.shard(index=1, num_shards=100),  # https://huggingface.co/docs/datasets/processing.html#sharding-the-dataset-shard\n","    eval_dataset=dataset[\"test\"],  #.shard(index=1, num_shards=100),\n","    compute_metrics=lambda eval_pred: compute_metrics_nli_binary(eval_pred, label_text_alphabetical=label_text_alphabetical)\n",")\n","\n","trainer.train()\n"],"metadata":{"id":"e3ymtsQtxVzx","colab":{"base_uri":"https://localhost:8080/","height":620},"executionInfo":{"status":"ok","timestamp":1684778466145,"user_tz":-60,"elapsed":945642,"user":{"displayName":"Yara Kyrychenko","userId":"07690358214170724243"}},"outputId":"98df3626-e316-419e-aabd-4dca135ec60f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["The following columns in the training set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: hypothesis, label_nli_explicit, text_prepared. If hypothesis, label_nli_explicit, text_prepared are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 2220\n","  Num Epochs = 8\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2224\n","/usr/local/lib/python3.10/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:745: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  attention_scores = torch.bmm(query_layer, key_layer.transpose(-1, -2)) / torch.tensor(\n","/usr/local/lib/python3.10/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:829: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  score += c2p_att / torch.tensor(scale, dtype=c2p_att.dtype)\n","/usr/local/lib/python3.10/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:852: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  score += p2c_att / torch.tensor(scale, dtype=p2c_att.dtype)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2224' max='2224' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2224/2224 15:44, Epoch 8/8]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.470100</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.195300</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.065100</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.022300</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=2224, training_loss=0.17064119007090012, metrics={'train_runtime': 944.8531, 'train_samples_per_second': 18.797, 'train_steps_per_second': 2.354, 'total_flos': 1611388912695120.0, 'train_loss': 0.17064119007090012, 'epoch': 8.0})"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["## Evaluate the fine-tuned model on the held-out test set\n","results = trainer.evaluate()\n"],"metadata":{"id":"dhCLUKZG__v1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(results)"],"metadata":{"id":"kWzFrtCY-HKv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684778479788,"user_tz":-60,"elapsed":7,"user":{"displayName":"Yara Kyrychenko","userId":"07690358214170724243"}},"outputId":"edb0e5e0-4a57-448a-c6c2-06b92f640525"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'eval_loss': 1.0843173265457153, 'eval_f1_macro': 0.8052970651395848, 'eval_f1_micro': 0.8725, 'eval_accuracy_balanced': 0.8188007644529384, 'eval_accuracy_not_b': 0.8725, 'eval_runtime': 13.78, 'eval_samples_per_second': 58.055, 'eval_steps_per_second': 1.814, 'epoch': 8.0}\n"]}]},{"cell_type":"markdown","source":["## Save and load your fine-tuned model"],"metadata":{"id":"k__JobJ6vuPi"}},{"cell_type":"markdown","source":["This segment provides code for saving the model to your hard-disk or for uploading it to the Hugging Face hub."],"metadata":{"id":"QQdcTrT-yWW7"}},{"cell_type":"code","source":["## first you need to connect to your google drive with your google account\n","from google.colab import drive\n","import os\n","drive.mount('/content/drive', force_remount=False)\n","#drive.flush_and_unmount()\n","\n","# insert the path where you want to save the model\n","os.chdir(\"/content/drive/My Drive/\")\n","print(os.getcwd())\n"],"metadata":{"id":"9NzeLxsLysX-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_custom_path = \"content/drive/My Drive/YOUR PATH HERE\"\n","trainer.save_model(output_dir=model_custom_path)"],"metadata":{"id":"YrrE5O3O_Yw9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Push to hub\n","# install necessary dependencies\n","!sudo apt-get install git-lfs\n","!huggingface-cli login"],"metadata":{"id":"-sj7P7u1xWAS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684778693453,"user_tz":-60,"elapsed":209334,"user":{"displayName":"Yara Kyrychenko","userId":"07690358214170724243"}},"outputId":"69e34d6f-ce1c-470d-afa2-975e94206434"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","git-lfs is already the newest version (2.9.2-1).\n","0 upgraded, 0 newly installed, 0 to remove and 24 not upgraded.\n","\n","    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n","    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n","    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n","    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n","    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n","    \n","    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n","Token: \n","Add token as git credential? (Y/n) Y\n","Token is valid.\n","\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n","You might have to re-authenticate when pushing to the Hugging Face Hub.\n","Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n","\n","git config --global credential.helper store\n","\n","Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n","Token has not been saved to git credential helper.\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful\n"]}]},{"cell_type":"code","source":["# load your models from disk\n","model = AutoModelForSequenceClassification.from_pretrained(model_custom_path)\n","tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True, model_max_length=512)  # we load the tokenizer from the original BERT-NLI model\n","\n","# https://huggingface.co/docs/transformers/main_classes/model#transformers.PreTrainedModel.push_to_hub\n","repo_id = 'enter your repo id'\n","model.push_to_hub(repo_id=repo_id)\n","tokenizer.push_to_hub(repo_id=repo_id)\n"],"metadata":{"id":"040Vwn-pxTfX"},"execution_count":null,"outputs":[]}]}